---
title: "Lecture 7 - Categorical Models"
format: 
  html:
    code-overflow: wrap
---

## [Check-In : A Quick Study](https://docs.google.com/forms/d/e/1FAIpQLSfJC8RLLtQf0Px0yz1nJjx-8CGXFrMcuUg_b3od54kHHPCEHQ/viewform?usp=sf_link)

-   No talking, no looking up answers!
-   Will use data in lecture :)

![](images/7_cattree.png){fig-align="center" width="485"}

## Announcements & Reminders :

-   **THE END IS NEAR.** Five lectures left. Actually this feels like a lot?
-   **Lab 7 : Start Analyzing Your Final Project Data!**
    -   Export data as a .csv
    -   Data cleaning :
        -   get rid of "Extra" columns & rows.
        -   rename variables –\> codebook
        -   convert likert scales ("1 - Strongly Disagree") to numbers (1)
    -   Descriptive Statistics.
    -   DO THIS IN SECTION WHERE YOU CAN GET HELP!!!

## RECAP : $R^2$ In Real-Life

::: column-margin
![](images/clipboard-606508161.png)
:::

![](images/clipboard-1347662291.png)

-   **DISCUSS :** **what do these linear models tell us about the relationship between GPA, SAT (IVs) and freshman grades (DV)?**
    -   answers.
    -   go.
    -   here.

## When the IV is Categorical...

### We Load the Data

```{r}
d <- read.csv("~/Dropbox/!WHY STATS/Class Datasets/101 - Class Datasets - FA25/mini_cal_data.csv", stringsAsFactors = T)
```

### We Graph our Variables.

```{r}
hist(d$is.happy)
plot(d$stoned72) # an empty level!
levels(d$stoned72)[1] <- NA # careful, only do this one time.
plot(d$stoned72) # an empty level is GONE.
```

### We Define and Graph Our Linear Model.

The Model Coefficients : An Intercept and Slope

```{r}
mod <- lm(is.happy ~ stoned72, data = d)
coef(mod)
```

The Graph Will Help Our Interpretation.

```{r}
library(gplots)
plotmeans(is.happy ~ stoned72, data = d)
coef(mod)
summary(mod)$r.squared
```

-   The IV has been DUMMY CODED.
    -   when stoned72 = 0 = "No" (Or not "Yes")
    -   when stoned72 = 1 = "Yes"
-   The Intercept is : The Predicted Value of Y when all X-Values are Zero.
    -   this means :
-   The Slope is : How our Predicted Value of Y changes when X changes by one.
    -   this means :

### We Interpret Our Linear Model.

-   **Stat Stuff : What are the important numbers?**
    -   What is the relationship?
    -   How strong is this relationship?
-   **Brain Stuff : What's the point?**
    -   [Why]{.underline} does this relationship in the data exist?
    -   [What other questions]{.underline} might we ask?
    -   [Who cares]{.underline} about this relationship? (How could we use this knowledge)?

### Work Time. 

**Define another linear model to predict a numeric DV from a categorical IV (with 2 levels.)**

-   Student Example :

```{r}

```

-   Student Example :

```{r}

```

## BREAK TIME.

## When there are 3 (or more levels...)

-   Still just a linear model!

**Anchoring Study : Example**

![](images/clipboard-3672991615.png)

-   **Question :** Will the number that people see BEFORE making their own rating influence their decision?

-   **Theory :**

    -   OPTION A: People who see a HIGHER number before making their own rating will make a HIGHER number than people who see the LOWER number.
    -   OPTION B : People who see a LOWER number before making their own rating will make a HIGHER number than people who see the HIGHER number.
    -   OPTION C : There will be NO DIFFERENCES between the groups.

-   **Linear Models :** DV \~ IV

-   **Data :** the “anchor_SP25.csv" dataset

    -   Load the data and check to make sure the data loaded correctly.
    -   Graph the variables; remove outliers and / or empty levels.

-   **Results :**

    -   Define your Linear Models
    -   Interpret Your Results

-   **Discuss :**

    -   Why do we observe this pattern?
    -   How could we use this knowledge in real-life?
    -   What other questions do you have? What else would you want to learn about?

## ALL DONE! YAY.
