sqrt(SST)/length(residuals)
sd(grad$PSYSCI)
grad$PSYSCI
hist(grad$PSYSCI)
selfes <- read.csv("../datasets/Self-Esteem Dataset/data.csv"
selfes <- read.csv("../datasets/Self-Esteem Dataset/data.csv")
selfes <- read.csv("../datasets/Self-Esteem Dataset/data.csv",
stringsAsFactors = T,
na.strings = "0", sep = "\t")
head(selfes)
hist(selfes$age)
hist(grad$class.excite)
mean(grad$class.excite, na.rm = T)
median(grad$class.excite, na.rm = T)
hist(grad$class.excite)
selfes <- read.csv("../datasets/Self-Esteem Dataset/data.csv",
+                    stringsAsFactors = T,
selfes <- read.csv("../datasets/Self-Esteem Dataset/data.csv",
stringsAsFactors = T,
na.strings = "0", sep = "\t")
hist(selfes$age)
selfes[selfes$age < 150, ]$age
selfes[selfes$age > 150, ]$age
selfes[selfes$age > 150, ]$age <- NA
selfes[selfes$age > 150, ]$age
selfes[selfes$age > 150, ]$age <- NA
selfes[selfes$age > 150, ]$age <- NA
selfes$age[selfes$age > 120]
selfes$age[selfes$age > 120] <- NA
hist(selfes$age)
selfes$age[selfes$age < 18] <- NA
hist(selfes$age)
hist(selfes$age, xlim = c(15,120))
hist(selfes$age, xlim = c(0,120))
selfes$age[selfes$age > 100]
selfes$age[selfes$age > 80]
selfes[selfes$age > 80]$age
selfes[selfes$age > 80,"age"]
na.omit(selfes[selfes$age > 80,"age"])
d <- read.csv("~/Dropbox/!GRADSTATS/Datasets/Protestant Work Ethic/data.csv")
head(d)
d <- read.csv("~/Dropbox/!GRADSTATS/Datasets/Protestant Work Ethic/data.csv", sep = "")
d <- read_csv("~/Dropbox/!GRADSTATS/Datasets/Protestant Work Ethic/data.csv")
head(d)
d <- read_csv("~/Dropbox/!GRADSTATS/Datasets/Protestant Work Ethic/data.csv", sep = "\t")
head(d)
d <- read.csv("~/Dropbox/!GRADSTATS/Datasets/Protestant Work Ethic/data.csv", sep = "\t")
head(d)
hist(d$Q1E)
hist(d$Q1E, breaks = 20)
hist(d$Q1E, breaks = 200)
hist(d$Q1E, breaks = 200,
main = "Response Time for Answering Question 1 [Protestant Work Ethic Data]")
hist(d$Q1E, breaks = 200,
main = "RT for Answering Q1 [Protestant Work Ethic Data]",
xlab = "Response Time (RT) in ms")
d <- read.csv("~/Dropbox/!GRADSTATS/Datasets/Protestant Work Ethic/data.csv", sep = "\t")
hist(d$Q1E, breaks = 200,
main = "RT for Answering Q1 [Protestant Work Ethic Data]",
xlab = "Response Time (RT) in ms",
col = 'black', bor = 'white')
hist(d$Q1E, breaks = 100,
main = "RT for Answering Q1 [Protestant Work Ethic Data]",
xlab = "Response Time (RT) in ms",
col = 'black', bor = 'white')
d <- read.csv("~/Dropbox/!GRADSTATS/Datasets/Protestant Work Ethic/data.csv", sep = "\t")
hist(d$Q1E, breaks = 100,
main = "RT for Answering Q1 [Protestant Work Ethic Data]",
xlab = "Response Time (RT) in ms",
col = 'black', bor = 'black')
mean(d$Q1E, na.rm = T)
median(d$Q1E, na.rm = T)
sd(d$Q1E, na.rm = T)
selfes <- read.csv("../datasets/Self-Esteem Dataset/data.csv",
stringsAsFactors = T,
na.strings = "0", sep = "\t")
poskey.df <- selfes[,c(1:2,4,6,7)] # pos-keyed items (from the codebook)
negkey.df <- selfes[,c(3,5,8:10)] # neg-keyed items (from the codebook)
negkeyR.df <- 5-negkey.df # reverse scoring the neg-keyed items
SELFES.DF <- data.frame(poskey.df, negkeyR.df) # bringing it all 2gether.
library(psych) # loading the library
alpha(SELFES.DF) # alpha reliability.
library(psych)
psych::alpha(SELFES.DF) # alpha reliability.
selfes$SELFES <- rowMeans(SELFES.DF, na.rm = T) # creating the scale
hist(selfes$SELFES, col = 'black', bor = 'white', # the graph
main = "Histogram of Self-Esteem",
xlab = "Self-Esteem Score", breaks = 15)
describe(selfes$SELFES)
s.self <- selfes[sample(1:nrow(selfes), nrow(selfes), replace = T),] # my data
bucket <- array()
for(i in c(1:1000)){ # starting the for-loop
s.self <- selfes[sample(1:nrow(selfes), nrow(selfes), replace = T),] # my sample
bucket[i] <- mean(s.self$SELFES) # saving sample mean to bucket
} # ending the for-loop
hist(bucket)
bucet
bucket
bucket <- array()
for(i in c(1:1000)){ # starting the for-loop
s.self <- selfes[sample(1:nrow(selfes), nrow(selfes), replace = T),] # my sample
bucket[i] <- mean(s.self$SELFES, na.rm = T) # saving sample mean to bucket
} # ending the for-loop
hist(bucket)
sd(bucket)
mean(selfes$SELFES, na.rm = T) + 1.96 * sd(bucket) # upper limit of 95% CI
mean(selfes$SELFES, na.rm = T) - 1.96 * sd(bucket) # lower limit of 95% CI
mean(selfes$SELFES, na.rm = T) # my original mean
mean(selfes$SELFES, na.rm = T) + 1.96 * sd(bucket) # upper limit of 95% CI for the mean
mean(selfes$SELFES, na.rm = T) - 1.96 * sd(bucket) # lower limit of 95% CI for the mean
hist(selfes$SELFES, col = 'black', bor = 'white',
main = "Self-Esteem", xlab = "Self-Esteem Score")
abline(v = mean(selfes$SELFES, na.rm = T), lwd = 5, col = 'black')
abline(v = mean(selfes$SELFES, na.rm = T) + 1.96 * sd(bucket), lty = 2, col = 'black')
abline(v = mean(selfes$SELFES, na.rm = T) - 1.96 * sd(bucket), lty = 2, col = 'black')
hist(selfes$SELFES, col = 'black', bor = 'white',
main = "Self-Esteem", xlab = "Self-Esteem Score")
abline(v = mean(selfes$SELFES, na.rm = T), lwd = 5, col = 'red')
abline(v = mean(selfes$SELFES, na.rm = T) + 1.96 * sd(bucket), lty = 2, col = 'red')
abline(v = mean(selfes$SELFES, na.rm = T) - 1.96 * sd(bucket), lty = 2, col = 'red')
hist(selfes$SELFES, col = 'black', bor = 'white',
main = "Self-Esteem", xlab = "Self-Esteem Score")
abline(v = mean(selfes$SELFES, na.rm = T), lwd = 5, col = 'red')
abline(v = mean(selfes$SELFES, na.rm = T) + 1.96 * sd(bucket), lty = 2, col = 'red', lwd = 1)
abline(v = mean(selfes$SELFES, na.rm = T) - 1.96 * sd(bucket), lty = 2, col = 'red', lwd = 1)
hist(selfes$SELFES, col = 'black', bor = 'white',
main = "Self-Esteem", xlab = "Self-Esteem Score")
abline(v = mean(selfes$SELFES, na.rm = T), lwd = 5, col = 'blue')
abline(v = mean(selfes$SELFES, na.rm = T) + 1.96 * sd(bucket), lty = 2, col = 'red', lwd = 1)
abline(v = mean(selfes$SELFES, na.rm = T) - 1.96 * sd(bucket), lty = 2, col = 'red', lwd = 1)
fd <- rnorm(100, mean = 100, sd = 15) # fake data
fd[1:10]
fd <- rnorm(100, mean = 100, sd = 15) # fake data
fd[1:10] <- rnorm(10, mean = 150, sd = 15)
mean(fd)
median(fd)
blah <- data.frame(mean.diff = NULL, median.diff = NULL)
blah
blah <- data.frame(mean.diff = NULL, median.diff = NULL)
for(i in c(1:1000)){
fd <- rnorm(100, mean = 100, sd = 15) # fake data
fd[1:10] <- rnorm(10, mean = 150, sd = 15)
blah[i,1] <- mean(fd) - 100
blah[i,2] <- median(fd) - 100
}
blah
blah
hist(blah$V1)
par(mfrow = c(1,2))
hist(blah$V1)
hist(blah$V2)
blah <- data.frame(mean.diff = NULL, median.diff = NULL)
for(i in c(1:1000)){
fd <- rnorm(100, mean = 100, sd = 15) # fake data
fd[1:10] <- rnorm(10, mean = 150, sd = 15)
blah$mean.diff[i] <- mean(fd) - 100
blah$median.diff[i] <- median(fd) - 100
}
blah <- data.frame(mean.diff = NULL, median.diff = NULL)
blah <- cbind(mean.diff = NULL, median.diff = NULL)
blah
for(i in c(1:1000)){
fd <- rnorm(100, mean = 100, sd = 15) # fake data
fd[1:10] <- rnorm(10, mean = 150, sd = 15)
blah$mean.diff[i] <- mean(fd) - 100
blah$median.diff[i] <- median(fd) - 100
}
blah
blah
for(i in c(1:1000)){
fd <- rnorm(100, mean = 100, sd = 15) # fake data
fd[1:10] <- rnorm(10, mean = 150, sd = 15)
blah$mean.diff[i] <- mean(fd) - 100
blah$median.diff[i] <- median(fd) - 100
}
blah
blah <- data.frame(mean.diff = NULL, median.diff = NULL)
for(i in c(1:1000)){
fd <- rnorm(100, mean = 100, sd = 15) # fake data
fd[1:10] <- rnorm(10, mean = 150, sd = 15)
blah$mean.diff[i] <- mean(fd) - 100
blah$median.diff[i] <- median(fd) - 100
}
blah <- data.frame(mean.diff = array(), median.diff = array())
for(i in c(1:1000)){
fd <- rnorm(100, mean = 100, sd = 15) # fake data
fd[1:10] <- rnorm(10, mean = 150, sd = 15)
blah$mean.diff[i] <- mean(fd) - 100
blah$median.diff[i] <- median(fd) - 100
}
blah <- data.frame(mean.diff = array(), median.diff = array())
for(i in c(1:1000)){
fd <- rnorm(100, mean = 100, sd = 15) # fake data
fd[1:10] <- rnorm(10, mean = 150, sd = 15)
blah[i,1] <- mean(fd) - 100
blah[i,2] <- median(fd) - 100
}
head(blah)
par(mfrow = c(1,2))
hist(blah$mean.diff)
hist(blah$median.diff)
sum(mean.diff > median.diff)
sum(blah$mean.diff > blah$median.diff)
blah2 <- data.frame(mean.diff = array(), median.diff = array(), sd = array())
blah2 <- data.frame(mean.diff = array(), median.diff = array(), sd = array())
for(j in c(5:20))){
blah2 <- data.frame(mean.diff = array(), median.diff = array(), sd = array())
for(j in c(5:20)){
blah <- data.frame(mean.diff = array(), median.diff = array())
for(i in c(1:1000)){
fd <- rnorm(100, mean = 100, sd = j) # fake data
fd[1:10] <- rnorm(10, mean = 150, sd = 15)
blah[i,1] <- mean(fd) - 100
blah[i,2] <- median(fd) - 100}
blah2[i,1] <- mean(blah[,1])
blah2[i,2] <- mean(blah[,2])
blah2[i,3] <- j
}
blah2
mean(blah[,1])
blah2 <- data.frame(mean.diff = array(), median.diff = array(), sd = array())
for(j in c(5:20)){
blah <- data.frame(mean.diff = array(), median.diff = array())
for(i in c(1:1000)){
fd <- rnorm(100, mean = 100, sd = j) # fake data
fd[1:10] <- rnorm(10, mean = 150, sd = 15)
blah[i,1] <- mean(fd) - 100
blah[i,2] <- median(fd) - 100}
blah2[j,1] <- mean(blah[,1])
blah2[j,2] <- mean(blah[,2])
blah2[j,3] <- j
}
blah2
p.meanworse <- array()
p.meanworse <- array()
blah <- data.frame(mean.diff = array(), median.diff = array())
for(i in c(1:1000)){
fd <- rnorm(100, mean = 100, sd = 15) # fake data
fd[1:10] <- rnorm(10, mean = 150, sd = 15)
blah[i,1] <- mean(fd) - 100
blah[i,2] <- median(fd) - 100
}
pmeanworse[1] <- sum(blah$mean.diff > blah$median.diff)
p.meanworse <- array()
blah <- data.frame(mean.diff = array(), median.diff = array())
for(i in c(1:1000)){
fd <- rnorm(100, mean = 100, sd = 15) # fake data
fd[1:10] <- rnorm(10, mean = 150, sd = 15)
blah[i,1] <- mean(fd) - 100
blah[i,2] <- median(fd) - 100
}
p.meanworse[1] <- sum(blah$mean.diff > blah$median.diff)
## With more outliers.
blah <- data.frame(mean.diff = array(), median.diff = array())
for(i in c(1:1000)){
fd <- rnorm(100, mean = 100, sd = 15) # fake data
fd[1:20] <- rnorm(20, mean = 150, sd = 15)
blah[i,1] <- mean(fd) - 100
blah[i,2] <- median(fd) - 100
}
p.meanworse[2] <- sum(blah$mean.diff > blah$median.diff)
## With a larger sample size
blah <- data.frame(mean.diff = array(), median.diff = array())
for(i in c(1:1000)){
fd <- rnorm(1000, mean = 100, sd = 15) # fake data
fd[1:10] <- rnorm(10, mean = 150, sd = 15)
blah[i,1] <- mean(fd) - 100
blah[i,2] <- median(fd) - 100
}
p.meanworse[3] <- sum(blah$mean.diff > blah$median.diff)
p.meanworse
title: "Lab 3 | Sampling Error and Bias - KEY"
title: "Lab 3 | Sampling Error and Bias - KEY"
title: "Lab 3 | Sampling Error and Bias - KEY"
title: "Lab 3; Sampling Error and Bias - KEY"
hist(selfes$age, col = 'black', bor = 'white', breaks = 200)
hist(selfes$age, col = 'black', bor = 'white', breaks = 20)
hist(selfes$age, col = 'black', bor = 'white', breaks = 50)
plot(selfes$age)
library(psych)
describe(selfes$age)
sd(selfes$age, na.rm = T)
mean(selfes$age, na.rm = T)
median(selfes$age, na.rm = T)
sd(selfes$age, na.rm = T)
range(selfes$age, na.rm = T)
selfes$age[selfes$age < 18 | selfes$age > 80]
selfes$age[selfes$age < 18 | selfes$age > 80] <- NA
selfes$age[selfes$age < 18 | selfes$age > 80] <- NA
hist(selfes$age, col = 'black', bor = 'white')
coinflip <- c(0,1) # defining a coin-flip.
unfair <- c(.7,.3) # not 50/50
sample(coinflip,1, prob = unfair) #
bucketoflies <- array()
for(i in c(1:10000)){
bucketoflies[i] <- sum(replicate(10, sample(coinflip,1, prob = unfair)))
}
hist(bucketoflies)
coinflip <- c(0,1) # defining a coin-flip.
unfair <- c(.8,.2) # not 50/50
sample(coinflip,1, prob = unfair) #
bucketoflies <- array()
for(i in c(1:10000)){
bucketoflies[i] <- sum(replicate(10, sample(coinflip,1, prob = unfair)))
}
hist(bucketoflies)
mean(bucketoflies)
median(bucketoflies)
mean(bucketoflies)
median(bucketoflies)
coinflip <- c(0,1) # defining a coin-flip.
unfair <- c(.8,.2) # not 50/50
sample(coinflip,1, prob = unfair) #
bucketoflies <- array()
for(i in c(1:100)){
bucketoflies[i] <- sum(replicate(10, sample(coinflip,1, prob = unfair)))
}
hist(bucketoflies)
mean(bucketoflies)
median(bucketoflies)
coinflip <- c(0,1) # defining a coin-flip.
unfair <- c(.8,.2) # not 50/50
sample(coinflip,1, prob = unfair) #
bucketoflies <- array()
for(i in c(1:100)){
bucketoflies[i] <- sum(replicate(10, sample(coinflip,1, prob = unfair)))
}
hist(bucketoflies)
mean(bucketoflies)
median(bucketoflies)
hist(bucketoflies)
mean(bucketoflies)
median(bucketoflies)
hist(bucketoflies)
mean(bucketoflies)
median(bucketoflies)
coinflip <- c(0,1) # defining a coin-flip.
unfair <- c(.99,.01) # not 50/50
sample(coinflip,1, prob = unfair) #
bucketoflies <- array()
for(i in c(1:100)){
bucketoflies[i] <- sum(replicate(10, sample(coinflip,1, prob = unfair)))
}
hist(bucketoflies)
mean(bucketoflies)
median(bucketoflies)
mean(bucketoflies)
median(bucketoflies)
mean(bucketoflies)
median(bucketoflies)
unfair <- c(.7,.3) # not 50/50
sample(coinflip,1, prob = unfair) #
bucketoflies <- array()
for(i in c(1:10000)){
bucketoflies[i] <- sum(replicate(10, sample(coinflip,1, prob = unfair)))
}
hist(bucketoflies)
## visualizing the mean
plot(grad$PSYSCI)
abline(h = mean(grad$PSYSCI), lwd = 5)
## quantifying errors (residuals)
residuals <- grad$PSYSCI - mean(grad$PSYSCI, na.rm = T)
SST <- sum(residuals^2)
SST
SST/length(residuals) # average of squared residuals (variance)
sqrt(SST/length(residuals)) # average of residuals, unsquared (standard deviation)
sd(grad$PSYSCI) # slightly higher
sqrt(SST/(length(residuals)-1)) # the 'real' equation; n-1 to inflate / adjust for small samples
grad <- read.csv("../Datasets/Grad Onboard 2025/grad_onboard_SP25.csv", # my data
stringsAsFactors = T, # converting strings to categorical factors
na.strings = "") # a way to handle missing data (blanks --> NA values)
grad <- read.csv("../Datasets/Grad Onboard 2025/grad_onboard_SP25.csv", # my data
stringsAsFactors = T, # converting strings to categorical factors
na.strings = "") # a way to handle missing data (blanks --> NA values)
## visualizing the mean
plot(grad$PSYSCI)
alpha(df) # the alpha reliability
## visualizing the mean
abline(h = mean(grad$PSYSCI), lwd = 5)
## visualizing the mean
abline(h = mean(grad$PSYSCI), lwd = 5)
## visualizing the mean
plot(grad$PSYSCI)
## visualizing the mean
plot(grad$PSYSCI)
## visualizing the mean
plot(grad$PSYSCI)
## visualizing the mean
plot(grad$PSYSCI)
plot(grad$PSYSCI)
grad$PSYSCI
grad <- read.csv("../Datasets/Grad Onboard 2025/grad_onboard_SP25.csv", # my data
stringsAsFactors = T, # converting strings to categorical factors
na.strings = "") # a way to handle missing data (blanks --> NA values)
names(grad[,c(25:31)]) # identifying the missing values
df <- grad[,c(25:31)] # creating a mini-data frame
names(df) # checking to make sure I did this correctly
df[,c(4,6:7)] <- 6-df[,c(4,6:7)] # reverse scoring the negatively-keyed
grad$PSYSCI <- rowMeans(df, na.rm = T) # a new variable
hist(grad$PSYSCI) # the graph
library(psych) #
psych::alpha(df) # the alpha reliability
describe(grad$PSYSCI) # descriptive stats
plot(grad$PSYSCI)
abline(h = mean(grad$PSYSCI), lwd = 5)
## quantifying errors (residuals)
residuals <- grad$PSYSCI - mean(grad$PSYSCI, na.rm = T)
SST <- sum(residuals^2)
SST
SST/length(residuals) # average of squared residuals (variance)
sqrt(SST/length(residuals)) # average of residuals, unsquared (standard deviation)
sd(grad$PSYSCI) # slightly higher
sqrt(SST/(length(residuals)-1)) # the 'real' equation; n-1 to inflate / adjust for small samples
## visualizing the mean
plot(grad$PSYSCI)
abline(h = mean(grad$PSYSCI), lwd = 5)
## quantifying errors (residuals)
residuals <- grad$PSYSCI - mean(grad$PSYSCI, na.rm = T)
SST <- sum(residuals^2)
SST
SST/length(residuals) # average of squared residuals (variance)
sqrt(SST/length(residuals)) # average of residuals, unsquared (standard deviation)
sd(grad$PSYSCI) # slightly higher
sqrt(SST/(length(residuals)-1)) # the 'real' equation; n-1 to inflate / adjust for small samples
d <- read.csv("~/Dropbox/!GRADSTATS/Datasets/Protestant Work Ethic/data.csv", sep = "\t")
## visualizing the mean
plot(grad$PSYSCI)
abline(h = mean(grad$PSYSCI), lwd = 5)
## quantifying errors (residuals)
residuals <- grad$PSYSCI - mean(grad$PSYSCI, na.rm = T)
SST <- sum(residuals^2)
SST
SST/length(residuals) # average of squared residuals (variance)
sqrt(SST/length(residuals)) # average of residuals, unsquared (standard deviation)
sd(grad$PSYSCI) # slightly higher
sqrt(SST/(length(residuals)-1)) # the 'real' equation; n-1 to inflate / adjust for small samples
d <- read.csv("../Datasets/Protestant Work Ethic/data.csv", sep = "\t")
hist(d$Q1E, breaks = 100,
main = "RT for Answering Q1 (Protestant Work Ethic Data)",
xlab = "Response Time (RT) in ms",
col = 'black', bor = 'black')
mean(d$Q1E, na.rm = T)
median(d$Q1E, na.rm = T)
sd(d$Q1E, na.rm = T)
coinflip <- c(0,1) # defining a coin-flip.
sample(coinflip,1) #
replicate(10, sample(coinflip,1))
sum(replicate(10, sample(coinflip,1)))
bucket <- array()
for(i in c(1:1000)){
bucket[i] <- sum(replicate(10, sample(coinflip,1)))
}
hist(bucket)
diceroll <- c(1:6) # defining a die
sample(diceroll,1) #
replicate(10, sample(diceroll,1))
sum(replicate(10, sample(diceroll,1)))
big.bucket <- array()
for(i in c(1:10000)){
big.bucket[i] <- sum(replicate(10, sample(diceroll,1)))
}
hist(big.bucket)
coinflip <- c(0,1) # defining a coin-flip.
unfair <- c(.7,.3) # not 50/50
sample(coinflip,1, prob = unfair) #
bucketoflies <- array()
for(i in c(1:10000)){
bucketoflies[i] <- sum(replicate(10, sample(coinflip,1, prob = unfair)))
}
hist(bucketoflies)
rnorm(10000000, mean = 100, sd = 10)
fakey <- rnorm(10000000, mean = 100, sd = 10)
length(fakey)
mean(fakey, na.rm = T)
hist(fakey)
abline(v = mean(fakey), lwd = 5)
?sample # our friend, the sample function
sample(1:10, 1) # are you vibing with R?
sample(1:length(fakey), 1) # are you REALLY vibing?
sample(1:length(fakey), 10) # a small sample
fakey[sample(1:length(fakey), 10)] # ten random individuals from fakey.
lilfakey <- fakey[sample(1:length(fakey), 10)] # ten random individuals from fakey.
mean(lilfakey)
hist(lilfakey)
abline(v = mean(lilfakey), lwd = 5)
lilfakey <- fakey[sample(1:length(fakey), 10)] # ten random individuals from fakey.
hist(lilfakey, xlim = c(50,150), ylim = c(0,5),
main = paste(c("mean=", round(mean(lilfakey), 4)), sep = ""))
abline(v = mean(lilfakey), lwd = 5)
plot(grad$PSYSCI)
plot(grad$PSYSCI)
plot(grad$PSYSCI)
plot(grad$PSYSCI)
plot(grad$PSYSCI)
plot(grad$PSYSCI)
plot(grad$PSYSCI)
grad$PSYSCI
plot(grad$PSYSCI)
## visualizing the mean
plot(grad$PSYSCI)
abline(h = mean(grad$PSYSCI), lwd = 5)
## quantifying errors (residuals)
residuals <- grad$PSYSCI - mean(grad$PSYSCI, na.rm = T)
SST <- sum(residuals^2)
SST
SST/length(residuals) # average of squared residuals (variance)
sqrt(SST/length(residuals)) # average of residuals, unsquared (standard deviation)
sd(grad$PSYSCI) # slightly higher
sqrt(SST/(length(residuals)-1)) # the 'real' equation; n-1 to inflate / adjust for small samples
plot(grad$PSYSCI)
abline(h = mean(grad$PSYSCI), lwd = 5)
head(rnorm(10000000, mean = 100, sd = 10))
