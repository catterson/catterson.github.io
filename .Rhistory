title = "Multilevel Model Regression Example")
#| warning: false
## Plotting Data
ggplot(d, aes(y = HowGoing, x = Timepoint)) +
geom_line() +
geom_point(size = 2) +
facet_wrap(~Username) +
geom_smooth(method = "lm", se = F, colour = "red", size = 1.25)
## MLM
mlm <- lmer(HowGoing ~ (1 | Username), data = d)
mlm2 <- lmer(HowGoing ~ Timepoint + (1 | Username), data = d)
mlm3 <- lmer(HowGoing ~ Timepoint + (Timepoint | Username), data = d)
summary(mlm3)
sample(0:1, nrow(h), replace = T, prob = c(.7, .3)) # using the sample function
h <- read.csv("~/Dropbox/!GRADSTATS/gradlab/Datasets/World Happiness Report - 2024/World-happiness-report-2024.csv", stringsAsFactors = T)
library(ggplot2)
library(jtools)
## Some data cleaning.
h$GDPcat <- ifelse(scale(h$Log.GDP.per.capita) > sd(h$Log.GDP.per.capita, na.rm = T), "High GDP", "Low GDP")
h$GDPcat <- as.factor(h$GDPcat)
plot(h$GDPcat)
ggplot(data = subset(h, !is.na(h$GDPcat)), aes(x = scale(Ladder.score), y = scale(Social.support), color = GDPcat)) +
geom_point(alpha = .5, position = "jitter") +
geom_smooth(method = "lm") + labs(title = "Check-In Graph") + ylab("Social Support") + xlab("Happiness (Ladder Score)") +
theme_apa()
mod1 <- lm(scale(Social.support) ~ scale(Log.GDP.per.capita), data = h)
mod2 <- lm(scale(Social.support) ~ scale(Ladder.score), data = h)
mod3 <- lm(scale(Social.support) ~ scale(Log.GDP.per.capita) + scale(Ladder.score), data = h)
mod4 <- lm(scale(Social.support) ~ scale(Ladder.score) * scale(Log.GDP.per.capita), data = h)
export_summs(mod1, mod2, mod3, mod4)
sample(0:1, nrow(h), replace = T, prob = c(.7, .3)) # using the sample function
set.seed(424242)
random.selection <- sample(0:1, nrow(h), replace = T, prob = c(.7, .3))
htrain <- h[random.selection == 0,]
htest <- h[random.selection == 1,]
## Model in training Data
train.mod <- lm(Social.support ~ Ladder.score * Log.GDP.per.capita, data = htrain)
summary(train.mod)
predict(train.mod) # the predicted values of the DV, based on our model.
## Applying the model to our testing dataset.
predict(train.mod, newdata = htest) # produces predicted values from our training model, using the testing data.
predval.test <- predict(train.mod, newdata = htest)  # saves these predicted values from the testing dataset.
## Calculating R^2
test.mod.resid <- htest$Social.support - predval.test
SSE <- sum(test.mod.resid^2, na.rm = T)
SSE
test.resid <- htest$Social.support - mean(htest$Social.support, na.rm = T)
sum(test.resid^2)
SST <- sum(test.resid^2, na.rm = T)
(SST - SSE)/SST
# install.packages("caret")
library(caret)
train.control <- trainControl(method = "LOOCV")
loocvmod <- train(Social.support ~ Ladder.score * Log.GDP.per.capita, data = h, method = "lm",
trControl = train.control, na.action = "na.omit")
print(loocvmod)
library(car)
vif(mod4) # doesn't seem like multicollinearity is a problem.
## creating a highly correlated second IV.
jitter(h$Healthy.life.expectancy, 300)
h$health2 <- jitter(h$Healthy.life.expectancy, 300)
plot(h$health2, h$Healthy.life.expectancy) # yup.
multimod <- lm(Ladder.score ~ Healthy.life.expectancy + health2, data = h) # both in the model.
summary(multimod) # results! Things look good....
vif(multimod) # ...but wait!
par(mfrow = c(2,2))
plot(mod4)
h <- read.csv("~/Dropbox/!GRADSTATS/gradlab/Datasets/World Happiness Report - 2024/World-happiness-report-2024.csv", stringsAsFactors = T)
library(ggplot2)
library(jtools)
## Some data cleaning.
h$GDPcat <- ifelse(scale(h$Log.GDP.per.capita) > sd(h$Log.GDP.per.capita, na.rm = T), "High GDP", "Low GDP")
h$GDPcat <- as.factor(h$GDPcat)
# plot(h$GDPcat) # making sure this re-leveling worked.
ggplot(data = subset(h, !is.na(h$GDPcat)), aes(x = scale(Ladder.score), y = scale(Social.support), color = GDPcat)) +
geom_point(alpha = .5, position = "jitter") +
geom_smooth(method = "lm") + labs(title = "Graph of an Interaction Effect from Lecture 10") + ylab("Social Support") + xlab("Happiness (Ladder Score)") +
theme_apa()
mod1 <- lm(scale(Social.support) ~ scale(Log.GDP.per.capita), data = h)
mod2 <- lm(scale(Social.support) ~ scale(Ladder.score), data = h)
mod3 <- lm(scale(Social.support) ~ scale(Log.GDP.per.capita) + scale(Ladder.score), data = h)
mod4 <- lm(scale(Social.support) ~ scale(Ladder.score) * scale(Log.GDP.per.capita), data = h)
export_summs(mod1, mod2, mod3, mod4, set_caption("Blah"))
export_summs(mod1, mod2, mod3, mod4, caption = "Linear Models for the Interaction Effect from Lecture 10")
export_summs(mod1, mod2, mod3, mod4, caption = "Linear Models for the Interaction Effect from Lecture 10")
export_summs(mod1, mod2, mod3, mod4, title = "Linear Models for the Interaction Effect from Lecture 10")
set.seed(42)
n <- 50
x <- seq(-3, 3, length.out = n)
y <- sin(x) + rnorm(n, sd = 0.3)
data <- data.frame(x = x, y = y)
# Create plot with overfitting polynomial regression (degree 10)
ggplot(data, aes(x = x, y = y)) +
geom_point(color = "orange", size = 2) +
stat_smooth(method = "lm", formula = y ~ poly(x, 10), se = FALSE, color = "blue", size = 1) +
labs(title = "Overfit Polynomial Regression (Degree 10)") +
theme_minimal()
set.seed(42)
n <- 100
x <- seq(-3, 3, length.out = n)
y <- sin(x) + cos(x) + tan(x) + rnorm(n, sd = 0.3)
data <- data.frame(x = x, y = y)
# Create plot with overfitting polynomial regression (degree 10)
ggplot(data, aes(x = x, y = y)) +
geom_point(color = "orange", size = 2) +
stat_smooth(method = "lm", formula = y ~ poly(x, 10), se = FALSE, color = "blue", size = 1) +
labs(title = "Overfit Polynomial Regression (Degree 10)") +
theme_minimal()
set.seed(42)
n <- 100
x <- seq(-3, 3, length.out = n)
y <- sin(x) + cos(x) + rnorm(n, sd = 0.3)
data <- data.frame(x = x, y = y)
# Create plot with overfitting polynomial regression (degree 10)
ggplot(data, aes(x = x, y = y)) +
geom_point(color = "orange", size = 2) +
stat_smooth(method = "lm", formula = y ~ poly(x, 10), se = FALSE, color = "blue", size = 1) +
labs(title = "Overfit Polynomial Regression (Degree 10)") +
theme_minimal()
set.seed(42)
n <- 100
x <- seq(-3, 3, length.out = n)
y <- sin(x) + rnorm(n, sd = 1)
data <- data.frame(x = x, y = y)
# Create plot with overfitting polynomial regression (degree 10)
ggplot(data, aes(x = x, y = y)) +
geom_point(color = "orange", size = 2) +
stat_smooth(method = "lm", formula = y ~ poly(x, 10), se = FALSE, color = "blue", size = 1) +
labs(title = "Overfit Polynomial Regression (Degree 10)") +
theme_minimal()
set.seed(42)
n <- 100
x <- seq(-3, 3, length.out = n)
y <- sin(x) + rnorm(n, sd = 1)
data <- data.frame(x = x, y = y)
# Create plot with overfitting polynomial regression (degree 10)
ggplot(data, aes(x = x, y = y)) +
geom_point(color = "orange", size = 2) +
stat_smooth(method = "lm", formula = y ~ poly(x, 50), se = FALSE, color = "blue", size = 1) +
labs(title = "Overfit Polynomial Regression (Degree 10)") +
theme_minimal()
# Create plot with overfitting polynomial regression (degree 10)
ggplot(data, aes(x = x, y = y)) +
geom_point(color = "orange", size = 2) +
stat_smooth(method = "lm", formula = y ~ poly(x, 15), se = FALSE, color = "blue", size = 1) +
labs(title = "Overfit Polynomial Regression (Degree 10)") +
theme_minimal()
ggplot(data, aes(x = x, y = y)) +
geom_point(color = "orange", size = 2) +
stat_smooth(method = "lm", formula = y ~ poly(x, 20), se = FALSE, color = "blue", size = 1) +
labs(title = "Overfit Polynomial Regression (Degree 10)") +
theme_minimal()
par(mfrow = c(2,2))
plot(mod4)
t <- datasets::Titanic
?t
d <- datasets::Titanic
?Titanic
library(gplots)
plotmeans(as.numeric(Survived) ~ Class, data = Titanic)
Titanic
t(Titanic)
table(Titanic)
set.seed(42)
n <- 100
x <- seq(-5, 5, length.out = n)
y <- sin(x) + rnorm(n, sd = 1)
data <- data.frame(x = x, y = y)
#
ggplot(data, aes(x = x, y = y)) +
geom_point(color = "orange", size = 2) +
stat_smooth(method = "lm", formula = y ~ poly(x, 20), se = FALSE, color = "blue", size = 1) +
labs(title = "Overfit Polynomial Regression (Degree 10)") +
theme_minimal()
#
ggplot(data, aes(x = x, y = y)) +
geom_point(color = "orange", size = 2) +
# stat_smooth(method = "lm", formula = y ~ poly(x, 20), se = FALSE, color = "blue", size = 1) +
# labs(title = "A Polynomial Regression (Degree 20)") +
theme_minimal()
#
ggplot(data, aes(x = x, y = y)) +
geom_point(size = 2) +
# stat_smooth(method = "lm", formula = y ~ poly(x, 20), se = FALSE, color = "blue", size = 1) +
# labs(title = "A Polynomial Regression (Degree 20)") +
theme_minimal()
ggplot(data, aes(x = x, y = y)) +
geom_point(size = 2) +
# stat_smooth(method = "lm", formula = y ~ poly(x, 20), se = FALSE, color = "red", size = 2) +
# labs(title = "Overfit Model ("20-Degree Polynomial IV") +
theme_minimal()
#
ggplot(data, aes(x = x, y = y)) +
#
ggplot(data, aes(x = x, y = y)) +
geom_point(size = 2) +
stat_smooth(method = "lm", formula = y ~ poly(x, 20), se = FALSE, color = "red", size = 2) +
labs(title = "Overfit Model (20-Degree Polynomial IV") +
theme_minimal()
set.seed(42)
n <- 100
x <- seq(-5, 5, length.out = n)
y <- sin(x) + rnorm(n, sd = 1)
data <- data.frame(x = x, y = y)
#
ggplot(data, aes(x = x, y = y)) +
geom_point(size = 2) +
stat_smooth(method = "lm", formula = y ~ poly(x, 20), se = FALSE, color = "red", size = 2) +
labs(title = "Overfit Model (20-Degree Polynomial IV") +
theme_minimal()
set.seed(42)
n <- 100
x <- seq(-5, 5, length.out = n)
y <- sin(x) + rnorm(n, sd = 1)
data <- data.frame(x = x, y = y)
#
ggplot(data, aes(x = x, y = y)) +
geom_point(size = 2) +
stat_smooth(method = "lm", formula = y ~ poly(x, 25), se = FALSE, color = "red", size = 2) +
labs(title = "Overfit Model (25-Degree Polynomial IV") +
theme_minimal()
-.81+.25
-.81+.58+.25
-.81+.58
-.81-.58+.25
#| echo: false
library(ggplot2)
# Fakin' some data.
set.seed(42)
n <- 100
x <- seq(-5, 5, length.out = n)
y <- sin(x) + rnorm(n, sd = 1)
data <- data.frame(x = x, y = y)
# Graphin the fake data.
ggplot(data, aes(x = x, y = y)) +
geom_point(size = 2) +
#stat_smooth(method = "lm", formula = y ~ poly(x, 25), se = FALSE, color = "red", size = 2) +
#labs(title = "Overfit Model (25-Degree Polynomial IV") +
theme_minimal()
rnorm(n)
library(ggplot2)
# Fakin' some data.
set.seed(42)
n <- 100
x <- seq(-5, 5, length.out = n)
y <- sin(x) + rnorm(n)
d <- data.frame(x, y)
# Graphin the fake data.
ggplot(data, aes(x = x, y = y)) +
geom_point(size = 2) +
#stat_smooth(method = "lm", formula = y ~ poly(x, 25), se = FALSE, color = "red", size = 2) +
#labs(title = "Overfit Model (25-Degree Polynomial IV") +
theme_minimal()
library(ggplot2)
# Fakin' some data.
set.seed(42)
n <- 100
x <- seq(-5, 5, length.out = n)
y <- sin(x) + rnorm(n)
d <- data.frame(x, y)
# Graphin the fake data.
ggplot(data, aes(x = x, y = y)) +
geom_point(size = 2) +
#stat_smooth(method = "lm", formula = y ~ poly(x, 25), se = FALSE, color = "red", size = 2) +
#labs(title = "Overfit Model (25-Degree Polynomial IV") +
theme_minimal()
library(ggplot2)
# Fakin' some data.
set.seed(42)
n <- 100
x <- seq(-5, 5, n)
y <- sin(x) + rnorm(n)
d <- data.frame(x, y)
# Graphin the fake data.
ggplot(data, aes(x = x, y = y)) +
geom_point(size = 2) +
#stat_smooth(method = "lm", formula = y ~ poly(x, 25), se = FALSE, color = "red", size = 2) +
#labs(title = "Overfit Model (25-Degree Polynomial IV") +
theme_minimal()
library(ggplot2)
# Fakin' some data.
set.seed(42)
n <- 100
x <- seq(-5, 5, n)
y <- sin(x) + rnorm(n)
d <- data.frame(x, y)
# Graphin the fake data.
ggplot(data, aes(x = x, y = y)) +
geom_point(size = 2) +
#stat_smooth(method = "lm", formula = y ~ poly(x, 25), se = FALSE, color = "red", size = 2) +
#labs(title = "Overfit Model (25-Degree Polynomial IV") +
theme_minimal()
library(ggplot2)
# Fakin' some data.
set.seed(42)
n <- 100
x <- seq(-5, 5, n)
y <- sin(x) + rnorm(n)
d <- data.frame(x, y)
# Graphin the fake data.
ggplot(data, aes(x = x, y = y)) +
geom_point(size = 2) +
#stat_smooth(method = "lm", formula = y ~ poly(x, 25), se = FALSE, color = "red", size = 2) +
#labs(title = "Overfit Model (25-Degree Polynomial IV") +
theme_minimal()
library(ggplot2)
# Fakin' some data.
set.seed(42)
n <- 100
x <- seq(-5, 5, n)
y <- sin(x) + rnorm(n)
d <- data.frame(x, y)
# Graphin the fake data.
ggplot(data, aes(x = x, y = y)) +
geom_point(size = 2) +
#stat_smooth(method = "lm", formula = y ~ poly(x, 25), se = FALSE, color = "red", size = 2) +
#labs(title = "Overfit Model (25-Degree Polynomial IV") +
theme_minimal()
library(ggplot2)
# Fakin' some data.
set.seed(42)
n <- 100
x <- seq(-5, 5, n)
y <- sin(x) + rnorm(n, sd = 2)
d <- data.frame(x, y)
# Graphin the fake data.
ggplot(data, aes(x = x, y = y)) +
geom_point(size = 2) +
#stat_smooth(method = "lm", formula = y ~ poly(x, 25), se = FALSE, color = "red", size = 2) +
#labs(title = "Overfit Model (25-Degree Polynomial IV") +
theme_minimal()
library(ggplot2)
# Fakin' some data.
set.seed(42)
n <- 100
x <- seq(-5, 5, n)
y <- sin(x) + rnorm(n, sd = 5)
d <- data.frame(x, y)
# Graphin the fake data.
ggplot(data, aes(x = x, y = y)) +
geom_point(size = 2) +
#stat_smooth(method = "lm", formula = y ~ poly(x, 25), se = FALSE, color = "red", size = 2) +
#labs(title = "Overfit Model (25-Degree Polynomial IV") +
theme_minimal()
library(ggplot2)
# Fakin' some data.
set.seed(42)
n <- 100
x <- seq(-5, 5, n)
y <- sin(x) + rnorm(n, sd = 5)
d <- data.frame(x, y)
# Graphin the fake data.
ggplot(data, aes(x = x, y = y)) +
geom_point(size = 2) +
stat_smooth(method = "lm", formula = y ~ poly(x, 25), se = FALSE, color = "red", size = 2) +
labs(title = "Overfit Model (25-Degree Polynomial IV") +
theme_minimal()
setwd("~/Dropbox/STATS/Psych 101/grading/SP25/SP2025 - CheckIns/")
setwd("~/Dropbox/STATS/Psych 101/grading/SP25/SP2025 - CheckIns/")
usernames <- read.csv("0.1_Stats_Onboard_SP25-2.csv")
names(usernames)
usernames <- usernames[,2:4]
names(usernames)[3] <- "SIS.User.ID"
head(usernames)
grades <- read.csv("../2025-05-22T1617_Grades-PSYCH_101-SP25.csv")
grades$Exam <- as.numeric(grades$Mega.Exam.Current.Score)
grades$Quiz <- as.numeric(grades$Quizzes.Unposted.Final.Score)
grades$Quiz <- as.numeric(grades$Quizzes.Current.Score)
as.numeric(grades$Quizzes.Current.Score)
roster <- grades
names(roster)
roster <- roster[,c(1:5, 80, 81)]
head(roster)
head(roster)
roster <- grades
names(roster)
roster <- roster[,c(1:5, 76:77)]
head(roster)
matched <- merge(roster, usernames, by = "SIS.User.ID", all.x = T, all.y = F)
write.csv(matched, "../rosteruser.csv", row.names = F) # fill in missing emails, then comment out so you don't accidentally erase them and have to redo (SP23...)
#write.csv(matched, "../rosteruser.csv", row.names = F) # fill in missing emails, then comment out so you don't accidentally erase them and have to redo (SP23...)
matched <- read.csv("../rosteruser.csv") # SEE ABOVE!! ^^
## THE CHECK-INS :)
path = list.files(pattern="*.csv")
path # paste transposed into excel file so can tell students which they missed.
# Load Data
ci.data <- list()
for (i in 1:length(path)){
hold <- read.csv(path[[i]])
hold <- hold[hold$Timestamp > "2025/01/01",] # note : errors mean missing data from this semester; identify i to find empty checkin
hold <- data.frame(hold[,2], 1)
names(hold) <- c("Username", paste("CI", i, sep = ""))
ci.data[[i]] <- hold[,1:2]
}
i
path = list.files(pattern="*.csv")
path # paste transposed into excel file so can tell students which they missed.
# Load Data
ci.data <- list()
for (i in 1:length(path)){
hold <- read.csv(path[[i]])
hold <- hold[hold$Timestamp > "2025/01/01",] # note : errors mean missing data from this semester; identify i to find empty checkin
hold <- data.frame(hold[,2], 1)
names(hold) <- c("Username", paste("CI", i, sep = ""))
ci.data[[i]] <- hold[,1:2]
}
i
path = list.files(pattern="*.csv")
path # paste transposed into excel file so can tell students which they missed.
# Load Data
ci.data <- list()
for (i in 1:length(path)){
hold <- read.csv(path[[i]])
hold <- hold[hold$Timestamp > "2025/01/01",] # note : errors mean missing data from this semester; identify i to find empty checkin
hold <- data.frame(hold[,2], 1)
names(hold) <- c("Username", paste("CI", i, sep = ""))
ci.data[[i]] <- hold[,1:2]
}
i
ci.data <- list()
for (i in 1:length(path)){
hold <- read.csv(path[[i]])
hold <- hold[hold$Timestamp > "2025/01/01",] # note : errors mean missing data from this semester; identify i to find empty checkin
hold <- data.frame(hold[,2], 1)
names(hold) <- c("Username", paste("CI", i, sep = ""))
ci.data[[i]] <- hold[,1:2]
}
path = list.files(pattern="*.csv")
path # paste transposed into excel file so can tell students which they missed.
# Load Data
ci.data <- list()
for (i in 1:length(path)){
hold <- read.csv(path[[i]])
hold <- hold[hold$Timestamp > "2025/01/01",] # note : errors mean missing data from this semester; identify i to find empty checkin
hold <- data.frame(hold[,2], 1)
names(hold) <- c("Username", paste("CI", i, sep = ""))
ci.data[[i]] <- hold[,1:2]
}
i
path = list.files(pattern="*.csv")
path # paste transposed into excel file so can tell students which they missed.
# Load Data
ci.data <- list()
for (i in 1:length(path)){
hold <- read.csv(path[[i]])
hold <- hold[hold$Timestamp > "2025/01/01",] # note : errors mean missing data from this semester; identify i to find empty checkin
hold <- data.frame(hold[,2], 1)
names(hold) <- c("Username", paste("CI", i, sep = ""))
ci.data[[i]] <- hold[,1:2]
}
i
path = list.files(pattern="*.csv")
path # paste transposed into excel file so can tell students which they missed.
# Load Data
ci.data <- list()
for (i in 1:length(path)){
hold <- read.csv(path[[i]])
hold <- hold[hold$Timestamp > "2025/01/01",] # note : errors mean missing data from this semester; identify i to find empty checkin
hold <- data.frame(hold[,2], 1)
names(hold) <- c("Username", paste("CI", i, sep = ""))
ci.data[[i]] <- hold[,1:2]
}
i
path = list.files(pattern="*.csv")
path # paste transposed into excel file so can tell students which they missed.
# Load Data
ci.data <- list()
for (i in 1:length(path)){
hold <- read.csv(path[[i]])
hold <- hold[hold$Timestamp > "2025/01/01",] # note : errors mean missing data from this semester; identify i to find empty checkin
hold <- data.frame(hold[,2], 1)
names(hold) <- c("Username", paste("CI", i, sep = ""))
ci.data[[i]] <- hold[,1:2]
}
i
for(i in 1:length(ci.data)){ # for when you don't forget to have all students have email
print(head(ci.data[[i]]))}
## MERGING
core <- matched
missing <- list()
for(i in c(1:length(ci.data))){
core <- merge(core, ci.data[[i]], by = "Username", all.x = TRUE, all.y = FALSE)
missing[[i]] <- subset(ci.data[[i]], !(Username %in% core$Username))
core <- unique(core)
}
## ORGANIZE DATA FROM MISSING FOLKS
missing
Merged=Reduce(function(x, y) merge(x, y,all.x=T, all.y = T,by="Username"),missing)
Merged$TOTAL <- rowSums(Merged[,2:length(Merged)], na.rm = T)
missingfolks <- unique(with(Merged, data.frame(Username, TOTAL))) # data frame of missing folks.
missingfolks # can use this list to ID missing usernames; fill in rosterusername dataset; then rerun script.
names(core)
core$CITOTAL <- rowSums(core[,10:ncol(core)], na.rm = T)
hist(core$CITOTAL)
write.csv(core, "../checkinsucb_SP25.csv", row.names = FALSE)
write.csv(missingfolks, "../missingfolks_SP25.csv", row.names = FALSE)
core$Exam
core$CITOTAL
summary(lm(EXAM ~ CIT, data = core))
summary(lm(Exam ~ CIT, data = core))
summary(lm(Exam ~ CITOTAL, data = core))
summary(lm(Quiz ~ CITOTAL, data = core))
summary(lm(Exam ~ CITOTAL, data = core))
grades
names(grades)
exams <- grades[,c(1:9)]
names(exams)
summary(lm(Exam ~ CITOTAL, data = core))
summary(lm(scale(Exam) ~ scale(CITOTAL), data = core))
mod <- lm(scale(Exam) ~ scale(CITOTAL), data = core)
summary(mod)
confint(mod)
