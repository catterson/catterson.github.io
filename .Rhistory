abline(v = mean(megatruthbucket), lwd = 5, col = 'red')
mean(megatruthbucket) # the mean
sd(megatruthbucket) # the standard deviation
d <- read.csv("../datasets/Onboarding Data/honor_onboard_FA25.csv", stringsAsFactors = T, na.strings = "")
par(mfrow = c(1,2))
hist(d$self.skills, breaks = c(0:5),
col = 'black', bor = 'white', main = "Computer Skills\n(Self-Perceptions)")
d <- read.csv("../datasets/Onboarding Data/honor_onboard_FA25.csv", stringsAsFactors = T, na.strings = "")
par(mfrow = c(1,2))
hist(d$self.skills, breaks = c(0:5),
col = 'black', bor = 'white', main = "Computer Skills\n(Self-Perceptions)")
hist(d$class.skills, breaks = c(0:5),
col = 'black', bor = 'white', main = "Computer Skills\n(Perceptions of Classmates)")
d[sample(1:nrow(d), nrow(d), replace = T), ] # same code, all as one line.
newclass <- d[sample(1:nrow(d), nrow(d), replace = T), ]
newclass$self.skills
mean(newclass$self.skills)
mean(d$self.skills)
mean(newclass$self.skills)
newclass <- d[sample(1:nrow(d), nrow(d), replace = T), ]
mean(newclass$self.skills)
newclass <- d[sample(1:nrow(d), nrow(d), replace = T), ]
mean(newclass$self.skills)
newclass <- d[sample(1:nrow(d), nrow(d), replace = T), ]
mean(newclass$self.skills)
newclass <- d[sample(1:nrow(d), nrow(d), replace = T), ]
mean(newclass$self.skills)
newclass <- d[sample(1:nrow(d), nrow(d), replace = T), ]
mean(newclass$self.skills)
newclass <- d[sample(1:nrow(d), nrow(d), replace = T), ]
mean(newclass$self.skills)
newclass <- d[sample(1:nrow(d), nrow(d), replace = T), ]
mean(newclass$self.skills)
newclass <- d[sample(1:nrow(d), nrow(d), replace = T), ]
mean(newclass$self.skills)
newclass <- d[sample(1:nrow(d), nrow(d), replace = T), ]
mean(newclass$self.skills)
newclass <- d[sample(1:nrow(d), nrow(d), replace = T), ]
mean(newclass$self.skills)
newclass <- d[sample(1:nrow(d), nrow(d), replace = T), ]
mean(newclass$self.skills)
newclass <- d[sample(1:nrow(d), nrow(d), replace = T), ]
mean(newclass$self.skills)
allmyclassesaregreat <- array()
allmyclassesaregreat <- array()
for(i in c(1:1000)){
newclass <- d[sample(1:nrow(d), nrow(d), replace = T), ]
allmyclassesaregreat[i] <- mean(newclass$self.skills)
}
hist(allmyclassesaregreat)
hist(d$self.skills, breaks = c(0:5),
col = 'black', bor = 'white', main = "Computer Skills\n(Self-Perceptions)")
SST <- sum((d$self.skills - mean(d$self.skills))^2) # defining the total error
SST
d <- read.csv("~/Dropbox/!WHY STATS/Class Datasets/101 - Class Datasets - FA25/mini_cal_data.csv", stringsAsFactors = T)
nrow(d)
nrow(d)
head(d)
hist(d$insta.followers)
hist(d$insta.follows)
## Q4. What is the average of this variable?
## (Round to two decimal places for the check-in)
mean(d$insta.follows)
## Q4. What is the average of this variable?
## (Round to two decimal places for the check-in)
mean(d$insta.follows, na.rm = T)
### POP QUIZ : where would the median have to be? (and why??)
## below the mean / same as mean / above the mean
median(d$insta.follows, na.rm = T)
## Q6. What is the standard deviation of hrs.sleep?
sd(d$insta.follows, na.rm = T)
hist(d$insta.followers)
## Q7. What does this number mean / who cares about this value?
#### how much the average person differs from the average of the distribution!
#### the difference is in EITHER DIRECTION.
## BONUS QUESTION : how would you "see" the SD on the graph????
m <- mean(d$insta.follows, na.rm = T) # the mean.
s <- sd(d$insta.follows, na.rm = T) # the sd
hist(d$insta.follows)
abline(v = m, lwd = 5)
abline(v = m, lwd = 5, col = 'gray')
abline(v = m, lwd = 5, col = 'darkgray')
abline(v = m, lwd = 5, col = 'black')
abline(v = s, lty = "dashed")
hist(d$insta.follows)
abline(v = m, lwd = 5, col = 'black')
abline(v = m + s, lty = "dashed")
abline(v = m - s, lty = "dashed")
mean(d$hrs.sleep)
mean(d$hrs.sleep, na.rm = T)
## Q8. What is the average hours of sleep (hrs.sleep) for students in the class?
hist(d$hrs.sleep)
summary(d$hrs.sleep)
sd(d$hrs.sleep, na.rm = T)
d$hrs.sleep[d$hrs.sleep > 10]
d$hrs.sleep[d$engage < 3]
d$hrs.sleep[d$engage > 3]
d$hrs.sleep[d$tuhobura == "rat"]
d$tuhobura
d$hrs.sleep[d$tuhobura == "rats"]
## MOVING ON...
d$hrs.sleep[d$hrs.sleep > 10]
d$hrs.sleep[d$hrs.sleep > 10] <- NA
hist(d$hrs.sleep)
d <- read.csv("~/Dropbox/!WHY STATS/Chapter Datasets/Personality and Random Numbers/personality_random_number_data.csv",
stringsAsFactors = T)
names(d)
## Q1. How many individuals are in this dataset?
nrow(d)
## Q2. How many variables are in this dataset?
ncol(d)
head(d)
## Q3. The variable E1 is individual responses to the question "I am the life of the party" - a measure of Extraversion.
hist(d$E1)
d <- read.csv("~/Dropbox/!WHY STATS/Chapter Datasets/Personality and Random Numbers/personality_random_number_data.csv",
stringsAsFactors = T)
## Q1. How many individuals are in this dataset?
nrow(d)
## Q2. How many variables are in this dataset?
ncol(d)
hist(d$E1)
mean(d$E1)
summary(d)
d$E1[d$E1 = 0]
d$E1[d$E1 == 0]
d$E1[d$E1 < 1]
d$E1[d$E1 < 1] <- NA
d$E2[d$E2 < 1] <- NA
d[d < 1]
d[d == 0]
d[d == 0] <- NA
hist(d$E5)
summary(d)
mean(d$E11)
mean(d)
d[d == 1]
names(d)
d[d == 1, 22:31]
names(d)
extra.df <- d[,22:31] # using the codebook to index the 10 extraversion items
head(extra.df) # checking to make sure I did this correctly
alpha(extra.df) # r is warning me that some are negatively keyed...
library(psych)
names(d)
d[,22:31]
extra.df <- d[,22:31] # using the codebook to index the 10 extraversion items
head(extra.df) # checking to make sure I did this correctly
alpha(extra.df)
alpha(extra.df, check.keys = T) # seeing that some are negatively keyed...
## look at the codebook and confirm these are negatively keyed
extraPOS <- extra.df[,c(1,3,5,7,9)] # defining the positively keyed items
extraNEG <- extra.df[,c(2,4,6,8,10)] # defining the negatively keyed items
extraNEG <- extra.df[,c(2,4,6,8,10)] # defining the negatively keyed items
extraNEG
6-extraNEG
extraNEG <- 6-extraNEG # reverse scoring my negatively keyed items
extraCLEAN <- cbind(extraPOS, extraNEG)
head(extraCLEAN)
alpha(extraCLEAN) # high alpha; hooray.
d$EXTRA <- rowMeans(extraCLEAN,   # 10 items into one variable.
na.rm = TRUE) # still calculate if there’s missing data
hist(d$EXTRA)                     # What do you learn / observe?
names(d)
library(psych)
names(d)
open.df <- d[,61:71] # using the codebook to index the 10 openversion items
head(open.df) # checking to make sure I did this correctly
alpha(open.df) # r is warning me that some are negatively keyed...
alpha(open.df, check.keys = T) # seeing that some are negatively keyed...
## look at the codebook and confirm these are negatively keyed
openPOS <- open.df[,c(1,3,5,7,9)] # defining the positively keyed items
openNEG <- open.df[,c(2,4,6,8,10)] # defining the negatively keyed items
openNEG <- 6-openNEG # reverse scoring my negatively keyed items
openCLEAN <- cbind(openPOS, openNEG)
head(openCLEAN)
alpha(openCLEAN) # high alpha; hooray.
alpha(openCLEAN) # high alpha; hooray.
openPOS <- open.df[,c(1,3,5,7,9, 10)] # defining the positively keyed items
openNEG <- open.df[,c(2,4,6,8)] # defining the negatively keyed items
openNEG <- 6-openNEG # reverse scoring my negatively keyed items
openCLEAN <- cbind(openPOS, openNEG)
head(openCLEAN)
alpha(openCLEAN) # high alpha; hooray.
open.df
open.df <- d[,62:71] # using the codebook to index the 10 openversion items
head(open.df) # checking to make sure I did this correctly
open.df <- d[,62:71] # using the codebook to index the 10 openversion items
head(open.df) # checking to make sure I did this correctly
alpha(open.df) # r is warning me that some are negatively keyed...
alpha(open.df, check.keys = T) # seeing that some are negatively keyed...
## look at the codebook and confirm these are negatively keyed
openPOS <- open.df[,c(1,3,5,7,9,10)] # defining the positively keyed items
openNEG <- open.df[,c(2,4,6,8)] # defining the negatively keyed items
openNEG <- 6-openNEG # reverse scoring my negatively keyed items
openCLEAN <- cbind(openPOS, openNEG)
head(openCLEAN)
alpha(openCLEAN) # high alpha; hooray.
openPOS <- open.df[,c(1,3,5,7,9)] # defining the positively keyed items
openNEG <- open.df[,c(2,4,6,8,10)] # defining the negatively keyed items
openNEG <- 6-openNEG # reverse scoring my negatively keyed items
openCLEAN <- cbind(openPOS, openNEG)
head(openCLEAN)
alpha(openCLEAN) # high alpha; hooray.
openPOS <- open.df[,c(1,3,5,7,9, 10)] # defining the positively keyed items
openNEG <- open.df[,c(2,4,6,8)] # defining the negatively keyed items
openNEG <- 6-openNEG # reverse scoring my negatively keyed items
openCLEAN <- cbind(openPOS, openNEG)
head(openCLEAN)
alpha(openCLEAN) # high alpha; hooray.
d$OPEN <- rowMeans(openCLEAN,   # 10 items into one variable.
na.rm = TRUE) # still calculate if there’s missing data
hist(d$OPEN)
## Adapt this Code to Define Another Personality Scale (BORD Activity).
# STEP 1: ORGANIZING THE ITEMS AND CHECKING THE ALPHA RELIABILITY
names(d)
neg.df <- d[,32:41]
head(neg.df) # checking to make sure I did this correctly
alpha(neg.df) # r is warning me that some are negatively keyed...
negPOS <- neg.df[,c(1,3,5,7,9,6,8,10)] # defining the positively keyed items
negNEG <- neg.df[,c(2,4)] # defining the negatively keyed items
negNEG <- 6-negNEG # reverse scoring my negatively keyed items
negCLEAN <- cbind(negPOS, negNEG)
head(negCLEAN)
alpha(negCLEAN) # high alpha; hooray.
d$NEG <- rowMeans(negCLEAN,   # 10 items into one variable.
na.rm = TRUE) # still calculate if there’s missing data
hist(d$NEG)
### loading datasets and libraries
install.packages("psych") # only ONE time!!!!
library(psych)
d <- read.csv("~/Dropbox/!WHY STATS/Class Datasets/214 - Class Datasets - FA25/Mini Dataset/mini_dvc_data.csv")
d <- read.csv("~/Dropbox/!WHY STATS/Class Datasets/214 - Class Datasets - FA25/Mini Dataset/mini_dvc_data.csv", stringsAsFactors = T)
head(d)
### removing outliers from a variable.
hist(hrs.sleep)
d <- read.csv("~/Dropbox/!WHY STATS/Class Datasets/214 - Class Datasets - FA25/Mini Dataset/mini_dvc_data.csv", stringsAsFactors = T)
### removing outliers from a variable.
hist(hrs.sleep)
### removing outliers from a variable.
hist(d$hrs.sleep)
### removing outliers from a variable.
hist(d$hrs.sleep, breaks = 15)
hist(d$hrs.sleep, breaks = 15, col = "lavender")
mean(d$hrs.sleep)
sd(d$hrs.sleep)
abline(v = mean(d$hrs.sleep), lwd = 5)
sd(d$hrs.sleep)
abline(v = mean(d$hrs.sleep) + sd(d$hrs.sleep), lwd = 5, lty = "dashed")
abline(v = mean(d$hrs.sleep) - sd(d$hrs.sleep), lwd = 5, lty = "dashed")
names(d)
plot(hrs.sleep ~ tired, data = d)
d$hrs.sleep[d$hrs.sleep < 24]
d$hrs.sleep[d$hrs.sleep > 20]
d$hrs.sleep[d$hrs.sleep > 20] <- NA
mean(d$hrs.sleep)
sd(d$hrs.sleep)
abline(v = mean(d$hrs.sleep), lwd = 5)
abline(v = mean(d$hrs.sleep) + sd(d$hrs.sleep), lwd = 5, lty = "dashed")
abline(v = mean(d$hrs.sleep) - sd(d$hrs.sleep), lwd = 5, lty = "dashed")
names(d)
## LINEAR MODEL PREVIEW.
plot(hrs.sleep ~ tired, data = d)
mod <- lm(hrs.sleep ~ tired, data = d)
mod <- lm(hrs.sleep ~ tired, data = d)
abline(mod, lwd = 5, col = 'red')
plot(hrs.sleep ~ bored, data = d)
mod <- lm(hrs.sleep ~ bored, data = d)
abline(mod, lwd = 5, col = 'red')
plot(tired ~ bored, data = d)
mod <- lm(tired ~ bored, data = d)
abline(mod, lwd = 5, col = 'red')
d$hrs.sleep[d$hrs.sleep > 20]
d <- read.csv("~/Dropbox/!WHY STATS/Class Datasets/214 - Class Datasets - FA25/Mini Dataset/mini_dvc_data.csv", stringsAsFactors = T)
head(d)
### removing outliers from a variable.
hist(d$hrs.sleep, breaks = 15, col = "lavender")
d <- read.csv("~/Dropbox/!WHY STATS/Class Datasets/214 - Class Datasets - FA25/Mini Dataset/mini_dvc_data.csv", stringsAsFactors = T)
head(d)
### graphing a variable.
hist(d$hrs.sleep, breaks = 15, col = "lavender")
mean(d$hrs.sleep)
sd(d$hrs.sleep)
abline(v = mean(d$hrs.sleep), lwd = 5)
abline(v = mean(d$hrs.sleep) + sd(d$hrs.sleep), lwd = 5, lty = "dashed")
abline(v = mean(d$hrs.sleep) - sd(d$hrs.sleep), lwd = 5, lty = "dashed")
d$hrs.sleep[d$hrs.sleep > 20]
##  d$hrs.sleep = in the dataset d look for the variable hrs.sleep
##  [d$hrs.sleep > 20] = indexing = asking R to point to values where d$hrs.sleep is greater than 20
d$hrs.sleep[d$hrs.sleep > 20] <- NA
## <- NA # assign NA to this value.
hist(d$hrs.sleep, breaks = 15, col = "lavender")
abline(v = mean(d$hrs.sleep, na.rm = T), lwd = 5)
abline(v = mean(d$hrs.sleep, na.rm = T) + sd(d$hrs.sleep, na.rm = T), lwd = 5, lty = "dashed")
abline(v = mean(d$hrs.sleep, na.rm = T) - sd(d$hrs.sleep, na.rm = T), lwd = 5, lty = "dashed")
m <- mean(d$hrs.sleep, na.rm = T)
s <- sd(d$hrs.sleep, na.rm = T)
m
## making this code ^^ look less junky!!!
mean(d$hrs.sleep)
selfes <- read.csv("~/Dropbox/!GRADSTATS/Datasets/Self-Esteem Dataset/data.csv",
stringsAsFactors = T,
na.strings = "0", sep = "\t")
## Q. What is the standard deviation of the variable age?
sd(d$age) # 15.02
d <- read.csv("~/Dropbox/!WHY STATS/Chapter Datasets/narcissism_data.csv", stringsAsFactors = T)
names(d)
library(psych)
## Q. How many individuals are in the dataset?
nrow(d) # 11243
## DO NOT REMOVE OUTLIERS YET!
## Q. What is the mean of the variable age.
describe(d$age)
mean(d$age) # 34.01
## Q. What is the median of the variable age?
median(d$age)
## Q. What is the standard deviation of the variable age?
sd(d$age) # 15.02
d <- read.csv("~/Dropbox/!WHY STATS/Class Datasets/214 - Class Datasets - FA25/Mini Dataset/mini_dvc_data.csv", stringsAsFactors = T)
## nrow(d) #
nrow(d)
plot(d$stoned72)
summary(d$stoned72)
names(d)
plot(selfes ~ height, data = d)
d$selfes
d$height
d$height[d$height > 80]
d$height[d$height > 80] <- NA
plot(selfes ~ height, data = d)
d$height[d$height < 20] <- NA
plot(selfes ~ height, data = d)
abline(lm(selfes ~ height, data = d))
plot(selfes ~ insta.follows, data = d)
abline(lm(selfes ~ insta.follows, data = d))
max(d$insta.follows)
max(d$insta.follows, na.rm = T)
max(scale(d$insta.follows), na.rm = T)
d <- read.csv("~/Dropbox/!GRADSTATS/Datasets/World Happiness Report - 2024/World-happiness-report-2024.csv", stringsAsFactors = T)
head(d)
hist(d$Ladder.score)
hist(d$Ladder.score, xlim = c(0,10))
d$Ladder.score
mean(d$Ladder.score)
d$Ladder.score[62] # country 62
d$Ladder.score[62] - mean(d$Ladder.score)
sd(d$Ladder.score)
(d$Ladder.score[62] - mean(d$Ladder.score))/sd(d$Ladder.score)
scale(d$Ladder.score)
cbind("Raw Score" == d$Ladder.score, "ZScore" == scale(d$Ladder.score))
data.frame("Raw Score" == d$Ladder.score, "ZScore" == scale(d$Ladder.score))
data.frame(cbind("Raw Score" == d$Ladder.score, "ZScore" == scale(d$Ladder.score)))
data.frame(cbind("Raw Score" = d$Ladder.score, "ZScore" = scale(d$Ladder.score)))
hist(d$Social.support)
mod <- lm(Ladder.score ~ Social.support, data = d)
plot(Ladder.score ~ Social.support, data = d)
abline(mod, lwd = 5)
abline(h = mean(d$Ladder.score))
abline(v = mean(d$Social.support))
mean(d$Social.support)
abline(v = mean(d$Social.support, na.rm = T))
mod <- lm(Ladder.score ~ Social.support, data = d) # define the model.
plot(Ladder.score ~ Social.support, data = d)
abline(mod, lwd = 5)
coef(mod)
coef(mod)
abline(h = mean(d$Ladder.score))
abline(v = mean(d$Social.support, na.rm = T))
## our prediction of happiness = 2.26 + 2.88 * Social.support
2.26 + 2.88 * 1
2.26 + 2.88 * .25
2.26 + 2.88 * 5
d$upperwhisker
cbind(d$lowerwhisker, d$Ladder.score, d$upperwhisker)
## THE BOOTSTRAPPING STUFF TO ESTIMATE SAMPLING ERROR.
mod <- lm(Ladder.score ~ Social.support, data = d) # define the model.
plot(Ladder.score ~ Social.support, data = d)
abline(mod, lwd = 5)
coef(mod)
d[sample(1:nrow(d), nrow(d), replace = T), ]
coef(mod)
coef(mod)[2]
nw <- d[sample(1:nrow(d), nrow(d), replace = T), ]
head(nw)
blah <- lm(Ladder.score ~ Social.support, data = nw) # same model, new data
blah
coef(blah)[2]
bucket[i] <- coef(blah)[2]
bucket <- array() # define a place to save our slopes.
bucket[i] <- coef(blah)[2] # save slope to bucket
i <- 1
bucket[i] <- coef(blah)[2] # save slope to bucket
bucket
bucket <- array() # define a place to save our slopes.
for(i in c(1:1000)){
nw <- d[sample(1:nrow(d), nrow(d), replace = T), ] # new data
blah <- lm(Ladder.score ~ Social.support, data = nw) # same model, new data
coef(blah)[2] # find slope
bucket[i] <- coef(blah)[2] # save slope to bucket
}
hist(bucket)
abline(v = mean(bucket), lwd = 5)
sd(bucket)
coef(mod)[2]
hist(bucket)
abline(v = coef(mod)[2], lwd = 5)
abline(v = coef(mod)[2] + sd(bucket), lwd = 1)
abline(v = coef(mod)[2] - sd(bucket), lwd = 1)
abline(v = coef(mod)[2], lwd = 5)
abline(v = coef(mod)[2] + 1.96 * sd(bucket), lwd = 2, lty = "dashed")
abline(v = coef(mod)[2] - 1.96 * sd(bucket), lwd = 2, lty = "dashed")
hist(bucket)
abline(v = coef(mod)[2], lwd = 5)
abline(v = coef(mod)[2] + 1.96 * sd(bucket), lwd = 2, lty = "dashed")
abline(v = coef(mod)[2] - 1.96 * sd(bucket), lwd = 2, lty = "dashed")
coef(mod)[2] + 1.96 * sd(bucket) # upper limit of slope, estimating sampling error
coef(mod)[2] + 1.96 * sd(bucket) # lower limit
coef(mod)[2] + 1.96 * sd(bucket) # upper limit of slope, estimating sampling error
coef(mod)[2] - 1.96 * sd(bucket) # lower limit
d <- read.csv("~/Library/CloudStorage/Dropbox/!WHY STATS/Class Datasets/101 - Class Datasets - FA25/mini_cal_data.csv", na.strings="", stringsAsFactors=TRUE)
View(d)
names(d)
nrow(d)
hist(d$stoned72)
d$stoned72 <- as.numeric(as.character(d$stoned72))
hist(d$stoned72)
as.numeric(as.character(d$stoned72))
d$stoned72 <- as.character(d$stoned72)
hist(d$stoned72)
d$stoned72 <- as.numeric(d$stoned72)
hist(d$stoned72)
as.numeric(d$stoned72)
d$stoned72
d <- read.csv("~/Library/CloudStorage/Dropbox/!WHY STATS/Class Datasets/101 - Class Datasets - FA25/mini_cal_data.csv", na.strings="", stringsAsFactors=TRUE)
plot(d$stoned72)
levels(d$stoned72)
d$stoned72
summary(d$stoned72)
summary(d)
d <- read.csv("~/Library/CloudStorage/Dropbox/!WHY STATS/Class Datasets/101 - Class Datasets - FA25/mini_cal_data.csv", stringsAsFactors=TRUE)
names(d)
nrow(d)
summary(d)
plot(d$stoned72)
levels(d$stoned72)
levels(d$stoned72)[1]
levels(d$stoned72)[1] <- NA
plot(d$stoned72)
summary(d$stoned72)
data.frame(d$selfes, d$is.happy, d$satlife, d$bored)
HAP.df <- data.frame(d$selfes, d$is.happy, d$satlife, d$bored)
head(HAP.df)
HAP.df <- cbind(d$selfes, d$is.happy, d$satlife, d$bored)
head(HAP.df)
HAP.df <- with(d, data.frame(selfes, is.happy, satlife, bored))
head(HAP.df)
HAP.df <- d[,c(7, 10, 20, 31)]
head(HAP.df)
alpha(HAP.df)
library(psych)
alpha(HAP.df)
d$bored
range(d$bored, na.rm = T)
10-d$bored
cbind("Regular" = d$bored, "Reverse Scored" = 10-d$bored)
HAP.df <- cbind(d$selfes, d$is.happy, d$satlife, 10-d$bored)
alpha(HAP.df)
HAP.df <- cbind(d$selfes, d$is.happy, d$satlife, 10-d$bored)
alpha(HAP.df)
alpha(HAP.df)
HAP.df
rowMeans(HAP.df)
rowMeans(HAP.df, na.rm = T)
d$HAPPY <-rowMeans(HAP.df, na.rm = T)
hist(d$HAPPY)
hist(d$HAPPY, xlim = c(0,10))
describe(d$HAPPY)
hist(d$HAPPY, xlim = c(0,50))
hist(d$HAPPY)
hist(d$HAPPY, xlim = c(0,10))
d$HAPPY[42]
d$HAPPY[42]
d$HAPPY[42] - mean(d$HAPPY, na.rm = T)
mean(d$HAPPY, na.rm = T)
d$HAPPY == mean(d$HAPPY, na.rm = T)
sd(d$HAPPY, na.rm = T)
(d$HAPPY[42] - mean(d$HAPPY, na.rm = T)) / sd(d$HAPPY, na.rm = T)
scale(d$HAPPY)
scale(d$HAPPY)[42]
(d$HAPPY[42] - mean(d$HAPPY, na.rm = T)) / sd(d$HAPPY, na.rm = T)
happyitisalmostover <- rowMeans(HAP.df, na.rm = T)
d$happyitisalmostover
d$happyitisalmostover
names(d)
max(d$HAPPY, na.rm = T)
scale(max(d$HAPPY, na.rm = T))
(9.5 - mean(d$HAPPY, na.rm = T))
(9.5 - mean(d$HAPPY, na.rm = T))/sd(d$HAPPY, na.rm = T)
d$stoned72 == "yes"
d$stoned72
d$stoned72 == "yes"
d[d$stoned72 == "yes",]
dstonedY <- d[d$stoned72 == "yes",]
dY <- d[d$stoned72 == "yes",]
dN <- d[d$stoned72 == "no",]
dY$HAPPY
dN$HAPPY
mean(dY$HAPPY, na.rm = T)
mean(dN$HAPPY, na.rm = T)
par(mfrow = c(1,2))
hist(dY$HAPPY, main = "Happiness (Was Stoned in Last 72 Hrs)")
hist(dN$HAPPY, main = "Happiness (Was Not Stoned)")
d[d$HAPPY > 3,]
