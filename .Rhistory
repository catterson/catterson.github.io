data.frame("Raw Score" == d$Ladder.score, "ZScore" == scale(d$Ladder.score))
data.frame(cbind("Raw Score" == d$Ladder.score, "ZScore" == scale(d$Ladder.score)))
data.frame(cbind("Raw Score" = d$Ladder.score, "ZScore" = scale(d$Ladder.score)))
hist(d$Social.support)
mod <- lm(Ladder.score ~ Social.support, data = d)
plot(Ladder.score ~ Social.support, data = d)
abline(mod, lwd = 5)
abline(h = mean(d$Ladder.score))
abline(v = mean(d$Social.support))
mean(d$Social.support)
abline(v = mean(d$Social.support, na.rm = T))
mod <- lm(Ladder.score ~ Social.support, data = d) # define the model.
plot(Ladder.score ~ Social.support, data = d)
abline(mod, lwd = 5)
coef(mod)
coef(mod)
abline(h = mean(d$Ladder.score))
abline(v = mean(d$Social.support, na.rm = T))
## our prediction of happiness = 2.26 + 2.88 * Social.support
2.26 + 2.88 * 1
2.26 + 2.88 * .25
2.26 + 2.88 * 5
d$upperwhisker
cbind(d$lowerwhisker, d$Ladder.score, d$upperwhisker)
## THE BOOTSTRAPPING STUFF TO ESTIMATE SAMPLING ERROR.
mod <- lm(Ladder.score ~ Social.support, data = d) # define the model.
plot(Ladder.score ~ Social.support, data = d)
abline(mod, lwd = 5)
coef(mod)
d[sample(1:nrow(d), nrow(d), replace = T), ]
coef(mod)
coef(mod)[2]
nw <- d[sample(1:nrow(d), nrow(d), replace = T), ]
head(nw)
blah <- lm(Ladder.score ~ Social.support, data = nw) # same model, new data
blah
coef(blah)[2]
bucket[i] <- coef(blah)[2]
bucket <- array() # define a place to save our slopes.
bucket[i] <- coef(blah)[2] # save slope to bucket
i <- 1
bucket[i] <- coef(blah)[2] # save slope to bucket
bucket
bucket <- array() # define a place to save our slopes.
for(i in c(1:1000)){
nw <- d[sample(1:nrow(d), nrow(d), replace = T), ] # new data
blah <- lm(Ladder.score ~ Social.support, data = nw) # same model, new data
coef(blah)[2] # find slope
bucket[i] <- coef(blah)[2] # save slope to bucket
}
hist(bucket)
abline(v = mean(bucket), lwd = 5)
sd(bucket)
coef(mod)[2]
hist(bucket)
abline(v = coef(mod)[2], lwd = 5)
abline(v = coef(mod)[2] + sd(bucket), lwd = 1)
abline(v = coef(mod)[2] - sd(bucket), lwd = 1)
abline(v = coef(mod)[2], lwd = 5)
abline(v = coef(mod)[2] + 1.96 * sd(bucket), lwd = 2, lty = "dashed")
abline(v = coef(mod)[2] - 1.96 * sd(bucket), lwd = 2, lty = "dashed")
hist(bucket)
abline(v = coef(mod)[2], lwd = 5)
abline(v = coef(mod)[2] + 1.96 * sd(bucket), lwd = 2, lty = "dashed")
abline(v = coef(mod)[2] - 1.96 * sd(bucket), lwd = 2, lty = "dashed")
coef(mod)[2] + 1.96 * sd(bucket) # upper limit of slope, estimating sampling error
coef(mod)[2] + 1.96 * sd(bucket) # lower limit
coef(mod)[2] + 1.96 * sd(bucket) # upper limit of slope, estimating sampling error
coef(mod)[2] - 1.96 * sd(bucket) # lower limit
d <- read.csv("~/Library/CloudStorage/Dropbox/!WHY STATS/Class Datasets/101 - Class Datasets - FA25/mini_cal_data.csv", na.strings="", stringsAsFactors=TRUE)
View(d)
names(d)
nrow(d)
hist(d$stoned72)
d$stoned72 <- as.numeric(as.character(d$stoned72))
hist(d$stoned72)
as.numeric(as.character(d$stoned72))
d$stoned72 <- as.character(d$stoned72)
hist(d$stoned72)
d$stoned72 <- as.numeric(d$stoned72)
hist(d$stoned72)
as.numeric(d$stoned72)
d$stoned72
d <- read.csv("~/Library/CloudStorage/Dropbox/!WHY STATS/Class Datasets/101 - Class Datasets - FA25/mini_cal_data.csv", na.strings="", stringsAsFactors=TRUE)
plot(d$stoned72)
levels(d$stoned72)
d$stoned72
summary(d$stoned72)
summary(d)
d <- read.csv("~/Library/CloudStorage/Dropbox/!WHY STATS/Class Datasets/101 - Class Datasets - FA25/mini_cal_data.csv", stringsAsFactors=TRUE)
names(d)
nrow(d)
summary(d)
plot(d$stoned72)
levels(d$stoned72)
levels(d$stoned72)[1]
levels(d$stoned72)[1] <- NA
plot(d$stoned72)
summary(d$stoned72)
data.frame(d$selfes, d$is.happy, d$satlife, d$bored)
HAP.df <- data.frame(d$selfes, d$is.happy, d$satlife, d$bored)
head(HAP.df)
HAP.df <- cbind(d$selfes, d$is.happy, d$satlife, d$bored)
head(HAP.df)
HAP.df <- with(d, data.frame(selfes, is.happy, satlife, bored))
head(HAP.df)
HAP.df <- d[,c(7, 10, 20, 31)]
head(HAP.df)
alpha(HAP.df)
library(psych)
alpha(HAP.df)
d$bored
range(d$bored, na.rm = T)
10-d$bored
cbind("Regular" = d$bored, "Reverse Scored" = 10-d$bored)
HAP.df <- cbind(d$selfes, d$is.happy, d$satlife, 10-d$bored)
alpha(HAP.df)
HAP.df <- cbind(d$selfes, d$is.happy, d$satlife, 10-d$bored)
alpha(HAP.df)
alpha(HAP.df)
HAP.df
rowMeans(HAP.df)
rowMeans(HAP.df, na.rm = T)
d$HAPPY <-rowMeans(HAP.df, na.rm = T)
hist(d$HAPPY)
hist(d$HAPPY, xlim = c(0,10))
describe(d$HAPPY)
hist(d$HAPPY, xlim = c(0,50))
hist(d$HAPPY)
hist(d$HAPPY, xlim = c(0,10))
d$HAPPY[42]
d$HAPPY[42]
d$HAPPY[42] - mean(d$HAPPY, na.rm = T)
mean(d$HAPPY, na.rm = T)
d$HAPPY == mean(d$HAPPY, na.rm = T)
sd(d$HAPPY, na.rm = T)
(d$HAPPY[42] - mean(d$HAPPY, na.rm = T)) / sd(d$HAPPY, na.rm = T)
scale(d$HAPPY)
scale(d$HAPPY)[42]
(d$HAPPY[42] - mean(d$HAPPY, na.rm = T)) / sd(d$HAPPY, na.rm = T)
happyitisalmostover <- rowMeans(HAP.df, na.rm = T)
d$happyitisalmostover
d$happyitisalmostover
names(d)
max(d$HAPPY, na.rm = T)
scale(max(d$HAPPY, na.rm = T))
(9.5 - mean(d$HAPPY, na.rm = T))
(9.5 - mean(d$HAPPY, na.rm = T))/sd(d$HAPPY, na.rm = T)
d$stoned72 == "yes"
d$stoned72
d$stoned72 == "yes"
d[d$stoned72 == "yes",]
dstonedY <- d[d$stoned72 == "yes",]
dY <- d[d$stoned72 == "yes",]
dN <- d[d$stoned72 == "no",]
dY$HAPPY
dN$HAPPY
mean(dY$HAPPY, na.rm = T)
mean(dN$HAPPY, na.rm = T)
par(mfrow = c(1,2))
hist(dY$HAPPY, main = "Happiness (Was Stoned in Last 72 Hrs)")
hist(dN$HAPPY, main = "Happiness (Was Not Stoned)")
d[d$HAPPY > 3,]
####################################################
## Chapter 6 : Linear Models
####################################################
## CHECK-IN.
d <- read.csv("~/Dropbox/!WHY STATS/Class Datasets/214 - Class Datasets - FA25/Mini Dataset/mini_dvc_data.csv", stringsAsFactors = T)
####################################################
## Chapter 6 : Linear Models
####################################################
## CHECK-IN.
d <- read.csv("~/Dropbox/!WHY STATS/Chapter Datasets/World-happiness-report-2024.csv", stringsAsFactors = T)
names(d)
head(d)
hist(d$Ladder.score)
## calculating the mean
hist(d$Ladder.score)
## calculating the mean
mean(d$Ladder.score)
summary(d$Ladder.score)
describe(d$Ladder.score)
####################################################
## Chapter 6 : Linear Models
####################################################
## CHECK-IN.
library(psych)
describe(d$Ladder.score)
summary(d$Ladder.score)
summary(d)
## finding the maximum and minimum values.
range(d$Ladder.score)
summary(d$Ladder.score)
max(d$Ladder.score)
## z-scores review. (why the f*!@& do we care about this???)
d$Ladder.score[42] # has a happiness of 6.287
## IT IS DIFFERENT FROM THE MEAN.
d$Ladder.score[42] - mean(d$Ladder.score) # difference from mean
sd(d$Ladder.score)
## ILLUSTRATING THIS.
hist(d$Ladder.score)
abline(v = mean(d$Ladder.score), lwd = 5)
abline(v = d$Ladder.score[42], col = 'blue', lwd = 2)
abline(v = mean(d$Ladder.score) + sd(d$Ladder.score), lty = 2) # the mean
abline(v = mean(d$Ladder.score) - sd(d$Ladder.score), lty = 2) # the mean
abline(v = mean(d$Ladder.score) - sd(d$Ladder.score), lty = 2, lwd = 2) # the mean
abline(v = mean(d$Ladder.score) + sd(d$Ladder.score), lty = 2, lwd = 2) # the mean
hist(d$Ladder.score)
abline(v = mean(d$Ladder.score), lwd = 5) # the mean
abline(v = d$Ladder.score[42], col = 'blue', lwd = 3) # the mean
abline(v = mean(d$Ladder.score) + sd(d$Ladder.score), lty = 2, lwd = 3) # the mean + sd
abline(v = mean(d$Ladder.score) - sd(d$Ladder.score), lty = 2, lwd = 3)
(d$Ladder.score[42] - mean(d$Ladder.score))/sd(d$Ladder.score)
scale(d$Ladder.score)[42]
cbind(d$Ladder.score, scale(d$Ladder.score))
max(scale(d$Ladder.score))
min(scale(d$Ladder.score))
round(mean(scale(d$Ladder.score)), 5)
mean(scale(d$Ladder.score))
plot(Ladder.score ~ Social.support, data = d)
plot(d$Ladder.score ~ d$Social.support)
plot(Ladder.score ~ Social.support, data = d)
plot(d$Ladder.score ~ d$Social.support)
mod <- lm(d$Ladder.score ~ d$Social.support)
abline(mod, lwd = 5, col = "gold")
coef(mod)
## use the model --> specific predictions.
## Ladder = 2.26 + 2.88 * social support
2.26 + 2.88 * .5
2.26 + 2.88 * 1.5
names(d)
names(d)[6:11]
## EXAMPLE : BALPRIT
plot(d$Ladder.score ~ d$Healthy.life.expectancy)
mod <- lm(d$Ladder.score ~ d$Healthy.life.expectancy)
abline(mod, lwd = 5, color = "gold")
abline(mod, lwd = 5, color = "gold")
abline(mod, lwd = 5, color = "gold")
abline(mod, lwd = 5, color = "gold")
abline(mod, lwd = 5, color = "gold")
abline(mod, lwd = 5, color = "gold")
abline(mod, lwd = 5, color = "gold")
abline(mod, lwd = 5, color = "gold")
abline(mod, lwd = 5, color = "gold")
abline(mod, lwd = 5, color = "gold")
abline(mod, lwd = 5, color = "gold")
abline(mod, lwd = 5, color = "gold")
abline(mod, lwd = 5, color = "gold")
abline(mod, lwd = 5, color = "gold")
abline(mod, lwd = 5, color = "gold")
abline(mod, lwd = 5, color = "gold")
abline(mod, lwd = 5, color = "gold")
abline(mod, lwd = 5, color = "gold")
abline(mod, lwd = 5, color = "gold")
abline(mod, lwd = 5, color = "gold")
abline(mod, lwd = 5, color = "gold")
abline(mod, lwd = 5, color = "gold")
abline(mod, lwd = 5, color = "gold")
abline(mod, lwd = 5, color = "gold")
abline(mod, lwd = 5, color = "gold")
abline(mod, lwd = 5, color = "gold")
abline(mod, lwd = 5, color = "gold")
abline(mod, lwd = 5, color = "gold")
abline(mod, lwd = 5, color = "gold")
abline(mod, lwd = 5, color = "gold")
abline(mod, lwd = 5, color = "gold")
abline(mod, lwd = 5, color = "gold")
abline(mod, lwd = 5, color = "gold")
abline(mod, lwd = 5, color = "gold")
abline(mod, lwd = 5, color = "gold")
abline(mod, lwd = 5, color = "gold")
abline(mod, lwd = 5, color = "gold")
abline(mod, lwd = 5, color = "gold")
abline(mod, lwd = 5, col = "gold")
plot(d$Ladder.score ~ d$Healthy.life.expectancy)
mod <- lm(d$Ladder.score ~ d$Healthy.life.expectancy)
abline(mod, lwd = 5, col = "gold")
coef(mod)
mod
hist(d$Healthy.life.expectancy)
range(d$Healthy.life.expectancy)
range(d$Healthy.life.expectancy, na.rm = T)
plot(d$Ladder.score ~ d$Healthy.life.expectancy)
mod <- lm(d$Ladder.score ~ d$Healthy.life.expectancy)
abline(mod, lwd = 5, col = "gold")
coef(mod)
plot(d$Ladder.score ~ d$Healthy.life.expectancy, xlim = c(0, 1))
mod <- lm(d$Ladder.score ~ d$Healthy.life.expectancy)
abline(mod, lwd = 5, col = "gold")
coef(mod)
## EXAMPLE : BALPRIT
plot(d$Ladder.score ~ d$Healthy.life.expectancy, xlim = c(0, 1), ylim = c(0,10))
mod <- lm(d$Ladder.score ~ d$Healthy.life.expectancy)
abline(mod, lwd = 5, col = "gold")
coef(mod)
## ladder = 2.70 + 5.44 * HLE
2.70 + 5.44 * 1
## OFFICE HOURS. 10/8/2025
## TOPICS
### functions happen to datasets
d <- read.csv("~/Dropbox/!WHY STATS/Chapter Datasets/World-happiness-report-2024.csv", stringsAsFactors = T)
nrow
nrow(d$Ladder.score)
## LOAD AND CHECK DATA (Problem 1)
d <- read.csv("~/Dropbox/!WHY STATS/Class Datasets/214 - Class Datasets - FA25/Mini Dataset/mini_dvc_data.csv", stringsAsFactors = T)
head(d)
nrow(d)
names(d)
## GRAPHING VARIABLES & REMOVING OUTLIERS (Problem 2)
hist(d$insta.followers)
summary(d$insta.followers)
summary(d$insta.followers
)
summary(d$insta.followers
hist(d$insta.followers)
summary(d$insta.followers
## GRAPHING VARIABLES & REMOVING OUTLIERS (Problem 2)
hist(d$insta.followers)
mean(d$insta.followers)
mean(d$insta.followers, na.rm = T)
m <- mean(d$insta.followers, na.rm = T)
m
d2 <- d
## GRAPHING VARIABLES & REMOVING OUTLIERS (Problem 2)
hist(d$insta.followers, breaks = 20)
abline(v = m, lwd = 5)
hist(d$insta.followers, breaks = 20,
main = "Insta Followers",
xlab = "Number of Followers")
sd(d$insta.followers, na.rm = T)
10/8
1+1
#### VARIABLE YOU THINK WILL PREDICT INSTA FOLLOWERS
names(d)
hist(d$fb.friends)
hist(d$fb.friends, breaks = 20)
## insta.followers ~ fb.friends
plot(d$insta.followers ~ d$fb.friends)
range(d$insta.followers, na.rm = T)
mod <- lm(d$insta.followers ~ d$fb.friends)
mod
abline(mod)
.42 * 100
386 - 42
### R-SQUARED.
summary(mod)$r.squared
plot(thirsty ~ hrs.sleep, data = d)
mod2 <- lm(thirsty ~ hrs.sleep, data = d)
abline(mod2)
plot(mod2)
hist(d$hrs.sleep)
d$hrs.sleep[d$hrs.sleep > 12]
d$sleepy <- d$hrs.sleep
hist(d$sleepy)
d$sleepy[d$sleepy > 12] <- NA
hist(d$sleepy)
plot(thirsty ~ sleepy, data = d)
mod3 <- lm(thirsty ~ sleepy, data = d)
abline(mod3)
summary(mod3)$r.squared
summary(mod3)$r.squared * 100
par(mfrow = c(2,2))
hist(d$thirsty)
hist(d$sleepy)
plot(thirsty ~ hrs.sleep, data = d, main = "With Outlier")
mod2 <- lm(thirsty ~ hrs.sleep, data = d)
abline(mod2)
plot(thirsty ~ sleepy, data = d, main = "Without Outlier")
mod3 <- lm(thirsty ~ sleepy, data = d)
abline(mod3)
hist(d$hrs.sleep)
plot(thirsty ~ hrs.sleep, data = d, main = "With Outlier")
plot(thirsty ~ sleepy, data = d, main = "Without Outlier")
plot(thirsty ~ sleepy, data = d, main = "Without Outlier")
par(mfrow = c(2,2))
hist(d$hrs.sleep)
hist(d$sleepy)
plot(thirsty ~ hrs.sleep, data = d, main = "With Outlier")
mod2 <- lm(thirsty ~ hrs.sleep, data = d)
abline(mod2)
plot(thirsty ~ sleepy, data = d, main = "Without Outlier")
mod3 <- lm(thirsty ~ sleepy, data = d)
abline(mod3)
plot(thirsty ~ sleepy, data = d, main = "Without Outlier")
d <- read.csv("~/Dropbox/!WHY STATS/Class Datasets/214 - Class Datasets - FA25/Mini Dataset/mini_dvc_data.csv", stringsAsFactors = T)
head(d)
nrow(d)
names(d)
d2 <- d # creating a copy of the dataset (not always needed!)
## GRAPHING VARIABLES & REMOVING OUTLIERS (Problem 2)
#### VARIABLE = INSTA.FOLLOWERS.
hist(d$insta.followers, breaks = 20,
main = "Insta Followers",
xlab = "Number of Followers")
m <- mean(d$insta.followers, na.rm = T) # assigning objects.
abline(v = m, lwd = 5) # illustrating the mean.
sd(d$insta.followers, na.rm = T)
summary(d$insta.followers)
#### VARIABLE YOU THINK WILL BEST PREDICT INSTA FOLLOWERS
names(d)
## fb.friends
## insta.follows
## satlife
hist(d$fb.friends, breaks = 20)
## DEFINE AND INTERPRET LINEAR MODELS.
## insta.followers ~ fb.friends # that's a squiggle!!!!
plot(d$insta.followers ~ d$fb.friends) # scatterplot
mod <- lm(d$insta.followers ~ d$fb.friends) # define the model w/ lm
mod # look at the coefficients
abline(mod) # add the line to your graph.
### things we notice.
##### as facebook friends increases, the number of insta followes is predicted to GO DOWN (a negative relationship)
### intercept = 386 = the predicted value of Y (insta.followers) when X is ZERO (someone wtih 0 fb.friends.)
### slope = -.42 = for every one facebook friend you gain, we predict that the person will have .42 FEWER followers in instagram.
## the line = model = insta.followers = 386 - .42 * fb.friends
## someone with 100 facebook friends....
## 386 - .42 * 100 = 386 - 42 = 344
## insta.followers ~ fb.friends # that's a squiggle!!!!
plot(d$insta.followers ~ d$fb.friends) # scatterplot
mod <- lm(d$insta.followers ~ d$fb.friends) # define the model w/ lm
mod # look at the coefficients
abline(mod) # add the line to your graph
summary(mod)$r.squared ### R-SQUARED.
## MINI-ACTIVITY
### professor eats lunch.
### students : choose ANOTHER variable to use as the IV in our model.
#### graph the variable; make sure no WRONG answers.
#### include in the model : plot(), lm(), abline()
plot(thirsty ~ hrs.sleep, data = d)
mod2 <- lm(thirsty ~ hrs.sleep, data = d)
abline(mod2)
plot(mod2) # diagnostic plots.
plot(thirsty ~ sleepy, data = d)
d$sleepy <- d$hrs.sleep
d$sleepy[d$sleepy > 12] <- NA
hist(d$sleepy)
plot(thirsty ~ sleepy, data = d)
d <- read.csv("~/Dropbox/!WHY STATS/Class Datasets/214 - Class Datasets - FA25/Mini Dataset/mini_dvc_data.csv", stringsAsFactors = T)
head(d)
nrow(d)
names(d)
d2 <- d # creating a copy of the dataset (not always needed!)
## GRAPHING VARIABLES & REMOVING OUTLIERS (Problem 2)
#### VARIABLE = INSTA.FOLLOWERS.
hist(d$insta.followers, breaks = 20,
main = "Insta Followers",
xlab = "Number of Followers")
m <- mean(d$insta.followers, na.rm = T) # assigning objects.
abline(v = m, lwd = 5) # illustrating the mean.
sd(d$insta.followers, na.rm = T)
summary(d$insta.followers)
#### VARIABLE YOU THINK WILL BEST PREDICT INSTA FOLLOWERS
names(d)
## fb.friends
## insta.follows
## satlife
hist(d$fb.friends, breaks = 20)
## DEFINE AND INTERPRET LINEAR MODELS.
## insta.followers ~ fb.friends # that's a squiggle!!!!
plot(d$insta.followers ~ d$fb.friends) # scatterplot
mod <- lm(d$insta.followers ~ d$fb.friends) # define the model w/ lm
mod # look at the coefficients
abline(mod) # add the line to your graph.
### things we notice.
##### as facebook friends increases, the number of insta followes is predicted to GO DOWN (a negative relationship)
### intercept = 386 = the predicted value of Y (insta.followers) when X is ZERO (someone wtih 0 fb.friends.)
### slope = -.42 = for every one facebook friend you gain, we predict that the person will have .42 FEWER followers in instagram.
## the line = model = insta.followers = 386 - .42 * fb.friends
## someone with 100 facebook friends....
## 386 - .42 * 100 = 386 - 42 = 344
## insta.followers ~ fb.friends # that's a squiggle!!!!
plot(d$insta.followers ~ d$fb.friends) # scatterplot
mod <- lm(d$insta.followers ~ d$fb.friends) # define the model w/ lm
mod # look at the coefficients
abline(mod) # add the line to your graph
summary(mod)$r.squared ### R-SQUARED.
## MINI-ACTIVITY
### professor eats lunch.
### students : choose ANOTHER variable to use as the IV in our model.
#### graph the variable; make sure no WRONG answers.
#### include in the model : plot(), lm(), abline()
plot(thirsty ~ hrs.sleep, data = d)
mod2 <- lm(thirsty ~ hrs.sleep, data = d)
abline(mod2)
# plot(mod2) # diagnostic plots.
d$sleepy <- d$hrs.sleep
d$sleepy[d$sleepy > 12] <- NA
hist(d$sleepy)
plot(thirsty ~ sleepy, data = d)
mod3 <- lm(thirsty ~ sleepy, data = d)
abline(mod3)
summary(mod3)$r.squared * 100 # as a percentage.
par(mfrow = c(2,2))
hist(d$hrs.sleep)
hist(d$sleepy)
plot(thirsty ~ hrs.sleep, data = d, main = "With Outlier")
mod2 <- lm(thirsty ~ hrs.sleep, data = d)
abline(mod2)
plot(thirsty ~ sleepy, data = d, main = "Without Outlier")
mod3 <- lm(thirsty ~ sleepy, data = d)
abline(mod3)
par(mfrow = c(2,2))
hist(d$hrs.sleep)
hist(d$sleepy)
plot(thirsty ~ hrs.sleep, data = d, main = "With Outlier", xlim = c(0,24))
mod2 <- lm(thirsty ~ hrs.sleep, data = d)
abline(mod2)
plot(thirsty ~ sleepy, data = d, main = "Without Outlier", xlim = c(0,24))
mod3 <- lm(thirsty ~ sleepy, data = d)
abline(mod3)
coef(mod2)
coef(mod3)
