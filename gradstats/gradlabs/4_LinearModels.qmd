---
title: "Lecture 4 | Linear Models"
format: 
  html:
    code-overflow: 'wrap'
---

![](images/clipboard-3051119200.png){fig-align="center" width="420"}

## [Check-In Here](https://docs.google.com/forms/d/e/1FAIpQLSe-5mOk5GyxloW5syXGjPQ4zayc4ZaeYHmzkroLxVz7uOP_Jg/viewform?usp=header)

1.  **Load the grad onboarding dataset (name this d to follow along with professor code in lecture).** The variable `can.forloop` asked students whether they could write a for-loop or not. What is the difference in the number of students who said that YES they could for-loop, compared to the number who said either NO or MAYBE? Find a way to get R to calculate this difference using code (hint : use indexing and the summary function.)

2.  **Now, write a for-loop to estimate how much sampling error might influence this number.** Generate 1000 new samples, and re-calculate the difference between YES and NO + MAYBEs. What percentage of re-sampled groups would show that there are more people who CAN write a for-loop than NO or MAYBE?

3.  **A bonus question.** R wrote you a secret message. Run the code below to see it.

```{r}
#| eval: false
#| include: true
greyScale <- colorRampPalette(c("pink","red"))
secretmessage <- function(r, col){
  t <- seq(0,2*pi,length.out=100)
  x <- r*sin(t)^3
  y <- (13*r/16)*cos(t) - (5*r/16)*cos(2*t) - (2*r/16)*cos(3*t) - (r/16)*cos(4*t)
  polygon(x,y,col=col,border=NA)
}

# create new plot canvas
plot.new()
# limits are approximate here
plot.window(xlim=c(-16,16),ylim=c(-16,13))

# use mapply to loop; invisible to turn off an annoying output.
invisible(mapply(secretmessage,seq(16,0,length.out=100),greyScale(100)))

## source : https://stackoverflow.com/questions/6542825/equation-driven-smoothly-shaded-concentric-shapes
## source : https://stackoverflow.com/questions/12984991/stop-lapply-from-printing-to-console
```

### Announcements & Agenda

**Agenda**

-   9:10 - 9:30 : Check-In and Review
-   9:30 - 10:30 : Linear Models (Basics)
-   10:30 - 11:00 : Break & Presentation
-   11:00 - 12:00 : Linear Models (Continued)

**Announcements**

-   **Discord!?!?**

-   **Lab Keys and Late Assignments.**

    -   would like to post key ASAP.

    -   but late labs + key = TROUBLE. Ideas?

-   **Mini Exam in TWO Weeks.**

    -   I give you data and a question, you generate a report in Quarto.

        -   Data loading and cleaning.

        -   Scale creating & descriptive statistics.

        -   Linear Models (TODAY!)

        -   Bootstrapping

        -   A fun challenge problem worth 1 point.

    -   Take home (9AM-12PM).

    -   Ask questions on ZOOM if / when you have them. Okay? Don't struggle on your own. Plenty of time to do that in other spaces!

    -   We will practice / review next week (Lab 5 a practice exam.)

    -   Think it will be chill, and if not then professor takes the blame, alright?

## RECAP : The Mean as Prediction

```{r}
#| include: false
d <- read.csv("../datasets/Grad Onboard 2025/grad_onboard_SP25.csv",
                           stringsAsFactors = T)
```

### The Mean is a Prediction (of the Sample)

::: panel-tabset
## Where is the Mean?

```{r}
plot(d$self.skills, 
     ylab = "Self-Perception of Skills",
     xlab = "Index") 
abline(h = mean(d$self.skills, na.rm = T), lwd = 0)
```

## There is the Mean!

```{r}
plot(d$self.skills, 
     ylab = "Self-Perception of Skills",
     xlab = "Index") 
abline(h = mean(d$self.skills, na.rm = T), lwd = 5)
```
:::

## There is Error in Our Prediction of the Sample (Residual Error)

This prediction of the sample has some error (residual error). We can (and will need to) quantify this error.

```{r}
## quantifying errors (residuals)
residuals <- d$self.skills - mean(d$self.skills, na.rm = T)
SST <- sum(residuals^2)
SST

SST/length(residuals) # average of squared residuals (variance)
sqrt(SST/length(residuals)) # average of residuals, unsquared (standard deviation)

sd(d$self.skills) # slightly higher
sqrt(SST/(length(residuals)-1)) # the 'real' equation; n-1 to inflate our estimate / adjust for small samples.
```

## The Mean is a Prediction of our Population (with Sampling Error)

```{r}
m <- array()
for(i in c(1:1000)){
 nd <- d[sample(1:nrow(d), nrow(d), replace = T),] # a new sample
 m[i] <- mean(nd$self.skills, na.rm = T)
}
mean(d$self.skills, na.rm = T)
mean(m) # similar!

sum(m > 2.5) # all of them (100% greater than the midpoint of the scale.)

sd(m) # sampling error!

hist(m, xlim = c(1,5)) # our distribution of sampling estimates 
abline(v = c(mean(d$self.skills),
             mean(d$self.skills) + 1.96 * sd(m),
             mean(d$self.skills) - 1.96 * sd(m)),
       lwd = c(5,2,2), # two line widths
       lty = c(1,2,2)) # two line types
```

## Linear Models : Improving our Predictions (Numeric IV)

### The Mean as a Model

```{r}
lm(self.skills ~ 1, data = d) # predicting self.skills from a constant (1), using the datset = d
mod0 <- lm(self.skills ~ 1, data = d) # saving this as a model object
coef(mod0) # looking at the coefficients
mod0$residuals # finding the residuals
```

### Use information in the IV to predict the DV

Let's try the same activity, but now we have graphed each individual's self-skill (still on the y-axis) in **relationship** to their perception of their classmates' skill (on the x-axis).

::: panel-tabset
## Where is the Line?

```{r}
plot(jitter(self.skills) ~ class.skills, data = d, 
     ylab = "Self-Perception of Skills",
     xlab = "Perception of Classmates' Skills") 
abline(lm(self.skills ~ class.skills, data = d), lwd = 0)
```

## There is the Line!

```{r}
plot(jitter(self.skills) ~ class.skills, data = d, 
     ylab = "Self-Perception of Skills",
     xlab = "Perception of Classmates' Skills") 
abline(lm(self.skills ~ class.skills, data = d), lwd = 5)
```
:::

**The Linear Model** :

![](images/clipboard-1514248515.png){fig-align="center" width="279"}

```{r}
mod1 <- lm(self.skills ~ class.skills, data = d)

par(mfrow = c(1,2))
plot(self.skills ~ class.skills, data = d, main = "Overlapping Data")
plot(jitter(self.skills) ~ class.skills, data = d, main = "Jittered Data") # jittered
abline(mod1, lwd = 5, col = 'red')

coef(mod1)
```

### There is Error in Our Prediction (residual error --\> R\^2)

```{r}
mod1$residuals # R does the residual calculation for us. what will happen if we add this up?

par(mfrow = c(1,2))
plot(d$self.skills, 
     ylab = "Self-Perception of Skills",
     xlab = "Index", main = "Mean as Model") 
abline(h = mean(d$self.skills, na.rm = T), lwd = 5)
plot(jitter(self.skills) ~ class.skills, data = d, main = "Linear Model") # jittered
abline(mod1, lwd = 5, col = 'red')
```

### There is Error in Our Prediction of the Population (sampling error)

```{r}
#| eval: false
#| include: true
bucket <- array()
for(i in c(1:1000)){
  ## what should go here?
}
hist(bucket) # what do we expect to see?
mean(bucket)
sd(bucket)
```

### Time for Another Example?

```{r}
names(d) # what other (numeric, for now) variable might predict self.skills?

```

## BREAK TIME : Meet Back at 10:40

## [Presentations](https://docs.google.com/presentation/d/1YZQ45_oj6TgiSIUpU7N6Ek5iTk2nn4T5RIpCz6Xi1K4/edit?usp=sharing)

## Linear Models : Improving our Predictions (Categorical IV)

### Use information in the IV to predict the DV

```{r}

```

### relevel() to aid interpretation.

```{r}

```

### Evaluate uncertainty in our prediction of the sample (R\^2)

```{r}

```

### Evaluate the uncertainty in our estimate of the population (sampling error)

```{r}

```

## Linear Models Again.

Load the gradmini.csv dataset. Check to make sure the data loaded correctly. Let's predict some variables.

```{r}

```

## FOR LAB 4.

1.  Define linear models to predict a numeric DV from a) a numeric IV and b) a categorical IV
2.  Interpret the intercept, slope, and R\^2 value.
